{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All models and their dependencies across all files:\n",
      "\n",
      "Model: deepset/roberta-base-squad2\n",
      "  haystack-ai: null\n",
      "  transformers: null\n",
      "\n",
      "Model: distilbert/distilbert-base-cased-distilled-squad\n",
      "  transformers: null\n",
      "\n",
      "Model: sjrhuschlee/flan-t5-large-squad2\n",
      "  transformers: null\n",
      "  torch: null\n",
      "  peft: null\n",
      "\n",
      "Model: google-bert/bert-large-uncased-whole-word-masking-finetuned-squad\n",
      "  torch: null\n",
      "\n",
      "Model: deepset/bert-large-uncased-whole-word-masking-squad2\n",
      "  haystack-ai: null\n",
      "  transformers: null\n",
      "\n",
      "Model: deepset/minilm-uncased-squad2\n",
      "  haystack-ai: null\n",
      "  transformers: null\n",
      "\n",
      "Model: distilbert/distilbert-base-uncased-distilled-squad\n",
      "  transformers: null\n",
      "\n",
      "Model: google-bert/bert-large-cased-whole-word-masking-finetuned-squad\n",
      "  torch: null\n",
      "\n",
      "Model: csarron/mobilebert-uncased-squad-v2\n",
      "  transformers: null\n",
      "\n",
      "Model: SmallDoge/Doge-160M-Instruct\n",
      "  transformers: null\n",
      "  trl: null\n",
      "\n",
      "Model: deepset/bert-base-cased-squad2\n",
      "  haystack-ai: null\n",
      "  transformers: null\n",
      "\n",
      "Model: deepset/roberta-large-squad2\n",
      "  transformers: null\n",
      "\n",
      "Model: Rifky/Indobert-QA\n",
      "  transformers: null\n",
      "\n",
      "Model: philschmid/distilbert-onnx\n",
      "  transformers: null\n",
      "  torch: null\n",
      "  onnx: null\n",
      "  onnxruntime: null\n",
      "\n",
      "Model: AgentPublic/camembert-base-squadFR-fquad-piaf\n",
      "  transformers: null\n",
      "\n",
      "Model: furiosa-ai/mlperf-bert-large\n",
      "  transformers: null\n",
      "\n",
      "Model: Rakib/roberta-base-on-cuad\n",
      "  transformers: null\n",
      "\n",
      "Model: timpal0l/mdeberta-v3-base-squad2\n",
      "  transformers: null\n",
      "\n",
      "Model: deepset/tinyroberta-squad2\n",
      "  transformers: null\n",
      "  torch: null\n",
      "  sentencepiece: null\n",
      "\n",
      "Model: HPAI-BSC/Llama3-Aloe-8B-Alpha\n",
      "  transformers: null\n",
      "  torch: null\n",
      "\n",
      "Model: deepset/roberta-base-squad2-distilled\n",
      "  haystack-ai: null\n",
      "  transformers: null\n",
      "\n",
      "Model: Praise2112/ModernBERT-base-squad2-v0.2\n",
      "  transformers: 4.48.0.dev0\n",
      "  pytorch: 2.5.1+cu124\n",
      "  datasets: 2.20.0\n",
      "  tokenizers: 0.21.0\n",
      "\n",
      "Model: SmallDoge/Doge-60M-Instruct\n",
      "  transformers: null\n",
      "\n",
      "Model: ahotrod/electra_large_discriminator_squad2_512\n",
      "  transformers: 2.11.0\n",
      "  pytorch: 1.5.0\n",
      "  tensorflow: 2.2.0\n",
      "  python: 3.8.1\n",
      "\n",
      "Model: deepset/deberta-v3-base-squad2\n",
      "  transformers: null\n",
      "  haystack-ai: null\n",
      "\n",
      "Model: SmallDoge/Doge-160M-Reason-Distill\n",
      "  transformers: null\n",
      "\n",
      "Model: SmallDoge/Doge-20M-Instruct\n",
      "  transformers: null\n",
      "\n",
      "Model: deepset/xlm-roberta-large-squad2\n",
      "  haystack-ai: null\n",
      "  transformers: null\n",
      "\n",
      "Model: amara16/distilbert-extractive-qa-project\n",
      "  transformers: null\n",
      "\n",
      "Model: umarigan/llama-3.1-openhermes-tr\n",
      "  transformers: null\n",
      "\n",
      "Model: Backedman/TriviaAnsweringMachineREAL\n",
      "  protobuf: null\n",
      "\n",
      "Model: deepset/bert-base-uncased-squad2\n",
      "  haystack-ai: null\n",
      "  transformers: null\n",
      "\n",
      "Model: houyu0930/test-demo-qa\n",
      "  transformers: null\n",
      "\n",
      "Model: mrm8488/bert-tiny-finetuned-squadv2\n",
      "  transformers: null\n",
      "\n",
      "Model: nes470/pipeline-as-repo\n",
      "  transformers: null\n",
      "\n",
      "Model: VietAI/vit5-base\n",
      "  transformers: null\n",
      "\n",
      "Model: sahilnishad/Florence-2-FT-DocVQA\n",
      "  torch: null\n",
      "  transformers: null\n",
      "  datasets: null\n",
      "  flash_attn: null\n",
      "\n",
      "Model: deepset/deberta-v3-large-squad2\n",
      "  transformers: null\n",
      "\n",
      "Model: phiyodr/bert-large-finetuned-squad2\n",
      "  transformers: null\n",
      "\n",
      "Model: bigwiz83/sapbert-from-pubmedbert-squad2\n",
      "  transformers: 4.7.0\n",
      "  pytorch: 1.8.0\n",
      "  datasets: 1.4.1\n",
      "  tokenizers: 0.10.2\n",
      "\n",
      "Model: pierreguillou/bert-base-cased-squad-v1.1-portuguese\n",
      "  transformers: null\n",
      "\n",
      "Model: deepset/gelectra-large-germanquad\n",
      "  haystack-ai: null\n",
      "  transformers: null\n",
      "\n",
      "Model: nathantablang/question-answering-qa-may-12-tablang-LOCAL\n",
      "  transformers: null\n",
      "\n",
      "Model: cross-encoder/ms-marco-MiniLM-L6-v2\n",
      "  sentence_transformers: null\n",
      "  transformers: null\n",
      "  torch: null\n",
      "\n",
      "Model: distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
      "  torch: null\n",
      "  transformers: null\n",
      "\n",
      "Model: papluca/xlm-roberta-base-language-detection\n",
      "  transformers: 4.12.5\n",
      "  pytorch: 1.10.0+cu111\n",
      "  datasets: 1.15.1\n",
      "  tokenizers: 0.10.3\n",
      "\n",
      "Model: microsoft/deberta-xlarge-mnli\n",
      "  torch: null\n",
      "  transformers: null\n",
      "\n",
      "Model: cardiffnlp/twitter-roberta-base-sentiment-latest\n",
      "  transformers: null\n",
      "  numpy: null\n",
      "  scipy: null\n",
      "\n",
      "Model: cardiffnlp/twitter-roberta-base-sentiment\n",
      "  transformers: null\n",
      "  numpy: null\n",
      "  scipy: null\n",
      "  csv: null\n",
      "  urllib: null\n",
      "\n",
      "Model: cross-encoder/ms-marco-MiniLM-L4-v2\n",
      "  sentence_transformers: null\n",
      "  transformers: null\n",
      "  torch: null\n",
      "\n",
      "Model: cardiffnlp/twitter-xlm-roberta-base-sentiment\n",
      "  transformers: null\n",
      "  numpy: null\n",
      "  scipy: null\n",
      "\n",
      "Model: lucadiliello/BLEURT-20-D12\n",
      "  torch: null\n",
      "  bleurt_pytorch: null\n",
      "\n",
      "Model: BAAI/bge-reranker-v2-m3\n",
      "  FlagEmbedding: null\n",
      "  torch: null\n",
      "  transformers: null\n",
      "\n",
      "Model: cardiffnlp/twitter-roberta-base-emotion\n",
      "  transformers: null\n",
      "  numpy: null\n",
      "  scipy: null\n",
      "  csv: null\n",
      "  urllib: null\n",
      "\n",
      "Model: yiyanghkust/finbert-tone\n",
      "  transformers: null\n",
      "\n",
      "Model: cross-encoder/ms-marco-MiniLM-L12-v2\n",
      "  sentence_transformers: null\n",
      "  transformers: null\n",
      "  torch: null\n",
      "\n",
      "Model: michellejieli/emotion_text_classifier\n",
      "  transformers: null\n",
      "\n",
      "Model: sadickam/sdgBERT\n",
      "  transformers: null\n",
      "\n",
      "Model: TieIncred/distilbert-base-uncased-finetuned-emotional\n",
      "  transformers: 4.16.2\n",
      "  pytorch: 2.1.0+cu118\n",
      "  datasets: 2.9.0\n",
      "  tokenizers: 0.14.1\n",
      "\n",
      "Model: lxyuan/distilbert-base-multilingual-cased-sentiments-student\n",
      "  transformers: 4.28.1\n",
      "  pytorch: 2.0.0+cu118\n",
      "  datasets: 2.11.0\n",
      "  tokenizers: 0.13.3\n",
      "\n",
      "Model: microsoft/deberta-large-mnli\n",
      "  torch: null\n",
      "  transformers: null\n",
      "\n",
      "Model: unitary/toxic-bert\n",
      "  transformers: null\n",
      "  pytorch_lightning: null\n",
      "  torch: null\n",
      "  pandas: null\n",
      "  detoxify: null\n",
      "\n",
      "Model: j-hartmann/emotion-english-distilroberta-base\n",
      "  transformers: null\n",
      "\n",
      "Model: finiteautomata/beto-sentiment-analysis\n",
      "  pysentimiento: null\n",
      "\n",
      "Model: Elron/bleurt-tiny-512\n",
      "  transformers: null\n",
      "  torch: null\n",
      "\n",
      "Model: martin-ha/toxic-comment-model\n",
      "  transformers: null\n",
      "\n",
      "Model: SamLowe/roberta-base-go_emotions\n",
      "  transformers: null\n",
      "\n",
      "Model: tals/albert-xlarge-vitaminc-mnli\n",
      "  datasets: null\n",
      "\n",
      "Model: mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\n",
      "  transformers: 4.10.2\n",
      "  pytorch: 1.9.0+cu102\n",
      "  datasets: 1.12.1\n",
      "  tokenizers: 0.10.3\n",
      "\n",
      "Model: cross-encoder/ms-marco-electra-base\n",
      "  sentence_transformers: null\n",
      "  transformers: null\n",
      "  torch: null\n",
      "\n",
      "Model: nbroad/ESG-BERT\n",
      "  torchserve: null\n",
      "  torch-model-archiver: null\n",
      "  torchvision: null\n",
      "  transformers: null\n",
      "\n",
      "Model: oliverguhr/german-sentiment-bert\n",
      "  germansentiment: null\n",
      "\n",
      "Model: madhurjindal/autonlp-Gibberish-Detector-492513457\n",
      "  torch: null\n",
      "  transformers: null\n",
      "\n",
      "Model: cross-encoder/ms-marco-MiniLM-L2-v2\n",
      "  sentence_transformers: null\n",
      "  transformers: null\n",
      "  torch: null\n",
      "\n",
      "Model: jinaai/jina-reranker-v2-base-multilingual\n",
      "  transformers: null\n",
      "  einops: null\n",
      "  sentence-transformers: null\n",
      "\n",
      "Model: WebOrganizer/TopicClassifier-NoURL\n",
      "  transformers: null\n",
      "  xformers: null\n",
      "  torch: null\n",
      "\n",
      "Model: cross-encoder/ms-marco-TinyBERT-L2-v2\n",
      "  transformers: null\n",
      "  torch: null\n",
      "  sentence_transformers: null\n",
      "\n",
      "Model: Alibaba-NLP/gte-multilingual-reranker-base\n",
      "  transformers: 4.36.0\n",
      "\n",
      "Model: finiteautomata/bertweet-base-sentiment-analysis\n",
      "  pysentimiento: null\n",
      "\n",
      "Model: amberoad/bert-multilingual-passage-reranking-msmarco\n",
      "  transformers: null\n",
      "\n",
      "Model: cross-encoder/mmarco-mMiniLMv2-L12-H384-v1\n",
      "  sentence_transformers: null\n",
      "  transformers: null\n",
      "  torch: null\n",
      "\n",
      "Model: tabularisai/multilingual-sentiment-analysis\n",
      "  transformers: null\n",
      "  torch: null\n",
      "\n",
      "Model: cross-encoder/stsb-roberta-base\n",
      "  sentence_transformers: null\n",
      "\n",
      "Model: jitesh/emotion-english\n",
      "  transformers: null\n",
      "\n",
      "Model: DiTy/cross-encoder-russian-msmarco\n",
      "  sentence-transformers: null\n",
      "  torch: null\n",
      "  transformers: null\n",
      "\n",
      "Model: cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual\n",
      "  tweetnlp: null\n",
      "\n",
      "Model: MoritzLaurer/ModernBERT-large-zeroshot-v2.0\n",
      "  transformers: 4.48.0.dev0\n",
      "  pytorch: 2.5.1+cu124\n",
      "  datasets: 3.2.0\n",
      "  tokenizers: 0.21.0\n",
      "\n",
      "Model: openai-community/gpt2\n",
      "  transformers: null\n",
      "\n",
      "Model: dslim/bert-base-NER\n",
      "  transformers: null\n",
      "\n",
      "Model: w11wo/indonesian-roberta-base-posp-tagger\n",
      "  transformers: 4.37.2\n",
      "  pytorch: 2.2.0+cu118\n",
      "  datasets: 2.16.1\n",
      "  tokenizers: 0.15.1\n",
      "\n",
      "Model: Babelscape/wikineural-multilingual-ner\n",
      "  transformers: null\n",
      "\n",
      "Model: gilf/french-camembert-postag-model\n",
      "  transformers: null\n",
      "\n",
      "Model: FacebookAI/xlm-roberta-large-finetuned-conll03-english\n",
      "  transformers: null\n",
      "\n",
      "Model: obi/deid_roberta_i2b2\n",
      "  spacy: null\n",
      "\n",
      "Model: MMG/xlm-roberta-large-ner-spanish\n",
      "  transformers: null\n",
      "\n",
      "Model: tsmatz/xlm-roberta-ner-japanese\n",
      "  transformers: 4.23.1\n",
      "  pytorch: 1.12.1+cu102\n",
      "  datasets: 2.6.1\n",
      "  tokenizers: 0.13.1\n",
      "\n",
      "Model: EvanD/xlm-roberta-base-romanian-ner-ronec\n",
      "  transformers: null\n",
      "\n",
      "Model: oliverguhr/fullstop-punctuation-multilang-large\n",
      "  deepmultilingualpunctuation: null\n",
      "\n",
      "Model: blaze999/Medical-NER\n",
      "  transformers: 4.37.0\n",
      "  pytorch: 2.1.2\n",
      "  datasets: 2.1.0\n",
      "  tokenizers: 0.15.1\n",
      "\n",
      "Model: microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank\n",
      "  llmlingua: null\n",
      "\n",
      "Model: Davlan/bert-base-multilingual-cased-ner-hrl\n",
      "  transformers: null\n",
      "\n",
      "Model: ckiplab/bert-base-chinese-ws\n",
      "  transformers: null\n",
      "\n",
      "Model: Davlan/distilbert-base-multilingual-cased-ner-hrl\n",
      "  transformers: null\n",
      "\n",
      "Model: Jean-Baptiste/camembert-ner\n",
      "  transformers: null\n",
      "\n",
      "Model: Jean-Baptiste/camembert-ner-with-dates\n",
      "  transformers: null\n",
      "\n",
      "Model: globis-university/deberta-v3-japanese-large\n",
      "  transformers: null\n",
      "\n",
      "Model: Jean-Baptiste/roberta-large-ner-english\n",
      "  transformers: null\n",
      "\n",
      "Model: dslim/bert-large-NER\n",
      "  transformers: null\n",
      "\n",
      "Model: Angelakeke/RaTE-NER-Deberta\n",
      "  transformers: null\n",
      "  torch: null\n",
      "\n",
      "Model: tner/roberta-large-ontonotes5\n",
      "  tner: null\n",
      "\n",
      "Model: ckiplab/bert-base-chinese-pos\n",
      "  transformers: null\n",
      "\n",
      "Model: 51la5/roberta-large-NER\n",
      "  transformers: null\n",
      "\n",
      "Model: yanekyuk/camembert-keyword-extractor\n",
      "  transformers: 4.19.2\n",
      "  pytorch: 1.11.0+cu113\n",
      "  datasets: 2.2.2\n",
      "  tokenizers: 0.12.1\n",
      "\n",
      "Model: sociocom/MedNERN-CR-JA\n",
      "  transformers: null\n",
      "  torch: null\n",
      "  numpy: null\n",
      "  pandas: null\n",
      "  tqdm: null\n",
      "  scikit-learn: null\n",
      "\n",
      "Model: ml6team/keyphrase-extraction-distilbert-inspec\n",
      "  transformers: null\n",
      "  numpy: null\n",
      "\n",
      "Model: syssec-utd/py312-pylingual-v1-segmenter\n",
      "  transformers: 4.48.2\n",
      "  pytorch: 2.2.1+cu121\n",
      "  datasets: 2.18.0\n",
      "  tokenizers: 0.21.0\n",
      "\n",
      "Model: ckiplab/bert-base-chinese-ner\n",
      "  transformers: null\n",
      "\n",
      "Model: savasy/bert-base-turkish-ner-cased\n",
      "  transformers: null\n",
      "\n",
      "Model: QCRI/bert-base-multilingual-cased-pos-english\n",
      "  transformers: null\n",
      "\n",
      "Model: pdelobelle/robbert-v2-dutch-ner\n",
      "  transformers: null\n",
      "\n",
      "Model: ckiplab/albert-tiny-chinese-ws\n",
      "  transformers: null\n",
      "\n",
      "Model: syafiqfaray/indobert-model-ner\n",
      "  transformers: 4.38.2\n",
      "  pytorch: 2.2.1+cu121\n",
      "  datasets: 2.18.0\n",
      "  tokenizers: 0.15.2\n",
      "\n",
      "Model: llm-book/bert-base-japanese-v3-ner-wikipedia-dataset\n",
      "  transformers: null\n",
      "\n",
      "Model: protectai/unbiased-toxic-roberta-onnx\n",
      "  optimum: null\n",
      "  transformers: null\n",
      "\n",
      "Model: microsoft/llmlingua-2-xlm-roberta-large-meetingbank\n",
      "  llmlingua: null\n",
      "\n",
      "Model: hatmimoha/arabic-ner\n",
      "  transformers: null\n",
      "  torch: null\n",
      "\n",
      "Model: NlpHUST/ner-vietnamese-electra-base\n",
      "  transformers: 4.20.1\n",
      "  pytorch: 1.8.0+cu111\n",
      "  datasets: 2.4.0\n",
      "  tokenizers: 0.12.1\n",
      "\n",
      "Model: Gherman/bert-base-NER-Russian\n",
      "  transformers: 4.28.1\n",
      "  pytorch: 1.13.0\n",
      "  datasets: 2.12.0\n",
      "  tokenizers: 0.13.3\n",
      "\n",
      "Models with non-null version dependencies across all files:\n",
      "\n",
      "Model: Praise2112/ModernBERT-base-squad2-v0.2\n",
      "  transformers: 4.48.0.dev0\n",
      "  pytorch: 2.5.1+cu124\n",
      "  datasets: 2.20.0\n",
      "  tokenizers: 0.21.0\n",
      "\n",
      "Model: ahotrod/electra_large_discriminator_squad2_512\n",
      "  transformers: 2.11.0\n",
      "  pytorch: 1.5.0\n",
      "  tensorflow: 2.2.0\n",
      "  python: 3.8.1\n",
      "\n",
      "Model: bigwiz83/sapbert-from-pubmedbert-squad2\n",
      "  transformers: 4.7.0\n",
      "  pytorch: 1.8.0\n",
      "  datasets: 1.4.1\n",
      "  tokenizers: 0.10.2\n",
      "\n",
      "Model: papluca/xlm-roberta-base-language-detection\n",
      "  transformers: 4.12.5\n",
      "  pytorch: 1.10.0+cu111\n",
      "  datasets: 1.15.1\n",
      "  tokenizers: 0.10.3\n",
      "\n",
      "Model: TieIncred/distilbert-base-uncased-finetuned-emotional\n",
      "  transformers: 4.16.2\n",
      "  pytorch: 2.1.0+cu118\n",
      "  datasets: 2.9.0\n",
      "  tokenizers: 0.14.1\n",
      "\n",
      "Model: lxyuan/distilbert-base-multilingual-cased-sentiments-student\n",
      "  transformers: 4.28.1\n",
      "  pytorch: 2.0.0+cu118\n",
      "  datasets: 2.11.0\n",
      "  tokenizers: 0.13.3\n",
      "\n",
      "Model: mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\n",
      "  transformers: 4.10.2\n",
      "  pytorch: 1.9.0+cu102\n",
      "  datasets: 1.12.1\n",
      "  tokenizers: 0.10.3\n",
      "\n",
      "Model: Alibaba-NLP/gte-multilingual-reranker-base\n",
      "  transformers: 4.36.0\n",
      "\n",
      "Model: MoritzLaurer/ModernBERT-large-zeroshot-v2.0\n",
      "  transformers: 4.48.0.dev0\n",
      "  pytorch: 2.5.1+cu124\n",
      "  datasets: 3.2.0\n",
      "  tokenizers: 0.21.0\n",
      "\n",
      "Model: w11wo/indonesian-roberta-base-posp-tagger\n",
      "  transformers: 4.37.2\n",
      "  pytorch: 2.2.0+cu118\n",
      "  datasets: 2.16.1\n",
      "  tokenizers: 0.15.1\n",
      "\n",
      "Model: tsmatz/xlm-roberta-ner-japanese\n",
      "  transformers: 4.23.1\n",
      "  pytorch: 1.12.1+cu102\n",
      "  datasets: 2.6.1\n",
      "  tokenizers: 0.13.1\n",
      "\n",
      "Model: blaze999/Medical-NER\n",
      "  transformers: 4.37.0\n",
      "  pytorch: 2.1.2\n",
      "  datasets: 2.1.0\n",
      "  tokenizers: 0.15.1\n",
      "\n",
      "Model: yanekyuk/camembert-keyword-extractor\n",
      "  transformers: 4.19.2\n",
      "  pytorch: 1.11.0+cu113\n",
      "  datasets: 2.2.2\n",
      "  tokenizers: 0.12.1\n",
      "\n",
      "Model: syssec-utd/py312-pylingual-v1-segmenter\n",
      "  transformers: 4.48.2\n",
      "  pytorch: 2.2.1+cu121\n",
      "  datasets: 2.18.0\n",
      "  tokenizers: 0.21.0\n",
      "\n",
      "Model: syafiqfaray/indobert-model-ner\n",
      "  transformers: 4.38.2\n",
      "  pytorch: 2.2.1+cu121\n",
      "  datasets: 2.18.0\n",
      "  tokenizers: 0.15.2\n",
      "\n",
      "Model: NlpHUST/ner-vietnamese-electra-base\n",
      "  transformers: 4.20.1\n",
      "  pytorch: 1.8.0+cu111\n",
      "  datasets: 2.4.0\n",
      "  tokenizers: 0.12.1\n",
      "\n",
      "Model: Gherman/bert-base-NER-Russian\n",
      "  transformers: 4.28.1\n",
      "  pytorch: 1.13.0\n",
      "  datasets: 2.12.0\n",
      "  tokenizers: 0.13.3\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# List of JSON files to process\n",
    "json_files = [\n",
    "    \"./model_analysis_type_question-answering_min_dl_1000_lib_transformers.json\",\n",
    "    \"./model_analysis_type_text-classification_min_dl_1000_lib_transformers.json\", \n",
    "    \"./model_analysis_type_text-generation_min_dl_1000_lib_transformers.json\",\n",
    "    \"./model_analysis_type_token-classification_min_dl_1000_lib_transformers.json\"\n",
    "]\n",
    "\n",
    "# Dictionary to store all models and their dependencies across files\n",
    "all_model_dependencies = {}\n",
    "models_with_version_info = {}\n",
    "\n",
    "# Process each JSON file\n",
    "for json_file in json_files:\n",
    "    try:\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        # Process models in current file\n",
    "        for model in data:\n",
    "            model_id = model['model_id']\n",
    "            deps = model.get('dependencies', [])\n",
    "            \n",
    "            if deps:\n",
    "                all_model_dependencies[model_id] = []\n",
    "                has_non_null_version = False\n",
    "                \n",
    "                for dep in deps:\n",
    "                    if len(dep) == 2:\n",
    "                        library, version = dep\n",
    "                        all_model_dependencies[model_id].append((library, version))\n",
    "                        if version is not None:\n",
    "                            has_non_null_version = True\n",
    "                \n",
    "                if has_non_null_version:\n",
    "                    models_with_version_info[model_id] = all_model_dependencies[model_id]\n",
    "                    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Could not find file {json_file}\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Warning: Error parsing JSON from {json_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Unexpected error processing {json_file}: {str(e)}\")\n",
    "\n",
    "print(\"\\nAll models and their dependencies across all files:\")\n",
    "for model_id, deps in all_model_dependencies.items():\n",
    "    print(f\"\\nModel: {model_id}\")\n",
    "    for lib, version in deps:\n",
    "        version_str = version if version is not None else \"null\"\n",
    "        print(f\"  {lib}: {version_str}\")\n",
    "\n",
    "print(\"\\nModels with non-null version dependencies across all files:\")\n",
    "for model_id, deps in models_with_version_info.items():\n",
    "    print(f\"\\nModel: {model_id}\")\n",
    "    for lib, version in deps:\n",
    "        version_str = version if version is not None else \"null\"\n",
    "        print(f\"  {lib}: {version_str}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers==4.48.0\n",
      "  Using cached transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting torch==2.5.1\n",
      "  Using cached torch-2.5.1-cp39-cp39-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting datasets==2.20.0\n",
      "  Using cached datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting tokenizers==0.21.0\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.48.0) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers==4.48.0)\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.48.0) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.48.0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.48.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.48.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.48.0) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.48.0) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.48.0) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.5.1) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.5.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.5.1) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.5.1) (2023.12.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.1)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.5.1) (12.4.127)\n",
      "Collecting triton==3.1.0 (from torch==2.5.1)\n",
      "  Using cached triton-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.5.1) (1.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==2.20.0) (19.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==2.20.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==2.20.0) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==2.20.0) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==2.20.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==2.20.0) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==2.20.0) (3.9.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.20.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.20.0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.20.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.20.0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.20.0) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.20.0) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.48.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.48.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.48.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.48.0) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from jinja2->torch==2.5.1) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas->datasets==2.20.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas->datasets==2.20.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas->datasets==2.20.0) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.20.0) (1.16.0)\n",
      "Using cached transformers-4.48.0-py3-none-any.whl (9.7 MB)\n",
      "Using cached torch-2.5.1-cp39-cp39-manylinux1_x86_64.whl (906.5 MB)\n",
      "Using cached datasets-2.20.0-py3-none-any.whl (547 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached triton-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "Downloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, huggingface-hub, torch, tokenizers, transformers, datasets\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
      "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.18.1\n",
      "    Uninstalling nvidia-nccl-cu12-2.18.1:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.18.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
      "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
      "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
      "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
      "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
      "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.17.3\n",
      "    Uninstalling huggingface-hub-0.17.3:\n",
      "      Successfully uninstalled huggingface-hub-0.17.3\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0\n",
      "    Uninstalling torch-2.1.0:\n",
      "      Successfully uninstalled torch-2.1.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.14.1\n",
      "    Uninstalling tokenizers-0.14.1:\n",
      "      Successfully uninstalled tokenizers-0.14.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.16.2\n",
      "    Uninstalling transformers-4.16.2:\n",
      "      Successfully uninstalled transformers-4.16.2\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.9.0\n",
      "    Uninstalling datasets-2.9.0:\n",
      "      Successfully uninstalled datasets-2.9.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "facenet-pytorch 2.6.0 requires torch<2.3.0,>=2.2.0, but you have torch 2.5.1 which is incompatible.\n",
      "facenet-pytorch 2.6.0 requires torchvision<0.18.0,>=0.17.0, but you have torchvision 0.21.0+cpu which is incompatible.\n",
      "gradio 4.44.1 requires aiofiles<24.0,>=22.0, but you have aiofiles 24.1.0 which is incompatible.\n",
      "gradio 4.44.1 requires markupsafe~=2.0, but you have markupsafe 3.0.2 which is incompatible.\n",
      "gradio 4.44.1 requires urllib3~=2.0, but you have urllib3 1.26.18 which is incompatible.\n",
      "torchaudio 2.5.0 requires torch==2.5.0, but you have torch 2.5.1 which is incompatible.\n",
      "torchvision 0.21.0+cpu requires torch==2.6.0, but you have torch 2.5.1 which is incompatible.\n",
      "xformers 0.0.20 requires torch==2.0.1, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-2.20.0 huggingface-hub-0.29.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.4.127 tokenizers-0.21.0 torch-2.5.1 transformers-4.48.0 triton-3.1.0\n"
     ]
    }
   ],
   "source": [
    "# Code Block 1: Praise2112/ModernBERT-base-squad2-v0.2\n",
    "!pip install transformers==4.48.0 torch==2.5.1 datasets==2.20.0 tokenizers==0.21.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1582cc24fc4b431c928ceb1fa6fff023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modelling.py:   0%|          | 0.00/4.97k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Praise2112/ModernBERT-base-squad2-v0.2:\n",
      "- modelling.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.modernbert.modeling_modernbert because of the following error (look up to see its traceback):\noperator torchvision::nms does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py:1817\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1818\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib64/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/modernbert/modeling_modernbert.py:35\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_rope_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ROPE_INIT_FUNCTIONS\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     37\u001b[0m     add_code_sample_docstrings,\n\u001b[1;32m     38\u001b[0m     add_start_docstrings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     logging,\n\u001b[1;32m     42\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/modeling_utils.py:51\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdpa_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sdpa_attention_forward\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LOSS_MAPPING\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     Conv1D,\n\u001b[1;32m     54\u001b[0m     apply_chunking_to_forward,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     translate_to_torch_parallel_style,\n\u001b[1;32m     61\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/loss/loss_utils.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BCEWithLogitsLoss, MSELoss\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_deformable_detr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_for_object_detection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ForObjectDetectionLoss, ForSegmentationLoss\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/loss/loss_deformable_detr.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m center_to_corners_format\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_scipy_available\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/image_transforms.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     ChannelDimension,\n\u001b[1;32m     24\u001b[0m     ImageInput,\n\u001b[1;32m     25\u001b[0m     get_channel_dimension_axis,\n\u001b[1;32m     26\u001b[0m     get_image_size,\n\u001b[1;32m     27\u001b[0m     infer_channel_dimension_format,\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExplicitEnum, TensorType, is_jax_tensor, is_tf_tensor, is_torch_tensor\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/image_utils.py:59\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torchvision_available():\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InterpolationMode\n\u001b[1;32m     61\u001b[0m     pil_torch_interpolation_mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     62\u001b[0m         PILImageResampling\u001b[38;5;241m.\u001b[39mNEAREST: InterpolationMode\u001b[38;5;241m.\u001b[39mNEAREST,\n\u001b[1;32m     63\u001b[0m         PILImageResampling\u001b[38;5;241m.\u001b[39mBOX: InterpolationMode\u001b[38;5;241m.\u001b[39mBOX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m         PILImageResampling\u001b[38;5;241m.\u001b[39mLANCZOS: InterpolationMode\u001b[38;5;241m.\u001b[39mLANCZOS,\n\u001b[1;32m     68\u001b[0m     }\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/__init__.py:10\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/_meta_registrations.py:164\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad\u001b[38;5;241m.\u001b[39mnew_empty((batch_size, channels, height, width))\n\u001b[1;32m    163\u001b[0m \u001b[38;5;129;43m@torch\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_fake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorchvision::nms\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43mmeta_nms\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mboxes should be a 2d tensor, got \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/library.py:795\u001b[0m, in \u001b[0;36mregister_fake.<locals>.register\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    794\u001b[0m     use_lib \u001b[38;5;241m=\u001b[39m lib\n\u001b[0;32m--> 795\u001b[0m \u001b[43muse_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_register_fake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstacklevel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/library.py:184\u001b[0m, in \u001b[0;36mLibrary._register_fake\u001b[0;34m(self, op_name, fn, _stacklevel)\u001b[0m\n\u001b[1;32m    182\u001b[0m     func_to_register \u001b[38;5;241m=\u001b[39m fn\n\u001b[0;32m--> 184\u001b[0m handle \u001b[38;5;241m=\u001b[39m \u001b[43mentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfake_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_to_register\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registration_handles\u001b[38;5;241m.\u001b[39mappend(handle)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/_library/fake_impl.py:31\u001b[0m, in \u001b[0;36mFakeImplHolder.register\u001b[0;34m(self, func, source)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready has an fake impl registered at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m     )\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_has_kernel_for_dispatch_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqualname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMeta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready has an DispatchKey::Meta implementation via a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: operator torchvision::nms does not exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForQuestionAnswering, AutoTokenizer\n\u001b[1;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPraise2112/ModernBERT-base-squad2-v0.2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForQuestionAnswering\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is dependency conflict?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:553\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_remote_code \u001b[38;5;129;01mand\u001b[39;00m trust_remote_code:\n\u001b[1;32m    552\u001b[0m     class_ref \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mauto_map[\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m]\n\u001b[0;32m--> 553\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m \u001b[43mget_class_from_dynamic_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m     _ \u001b[38;5;241m=\u001b[39m hub_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregister(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, model_class, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/dynamic_module_utils.py:553\u001b[0m, in \u001b[0;36mget_class_from_dynamic_module\u001b[0;34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# And lastly we get the class inside our newly created module\u001b[39;00m\n\u001b[1;32m    541\u001b[0m final_module \u001b[38;5;241m=\u001b[39m get_cached_module_file(\n\u001b[1;32m    542\u001b[0m     repo_id,\n\u001b[1;32m    543\u001b[0m     module_file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m     repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    552\u001b[0m )\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_class_in_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/dynamic_module_utils.py:250\u001b[0m, in \u001b[0;36mget_class_in_module\u001b[0;34m(class_name, module_path, force_reload)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# reload in both cases, unless the module is already imported and the hash hits\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__transformers_module_hash__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m!=\u001b[39m module_hash:\n\u001b[0;32m--> 250\u001b[0m     \u001b[43mmodule_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     module\u001b[38;5;241m.\u001b[39m__transformers_module_hash__ \u001b[38;5;241m=\u001b[39m module_hash\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, class_name)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/Praise2112/ModernBERT-base-squad2-v0.2/9ac2e5b645af19bb722bae2d14de3b8e030bd22a/modelling.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEntropyLoss\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModernBertModel, ModernBertPreTrainedModel, ModernBertConfig\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QuestionAnsweringModelOutput\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodernbert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_modernbert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModernBertPredictionHead\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1055\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py:1806\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1804\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1805\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m-> 1806\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[1;32m   1808\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py:1805\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1803\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[1;32m   1804\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1805\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1806\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py:1819\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1818\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1820\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1821\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1822\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.modernbert.modeling_modernbert because of the following error (look up to see its traceback):\noperator torchvision::nms does not exist"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "\n",
    "model_name = \"Praise2112/ModernBERT-base-squad2-v0.2\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "question = \"What is dependency conflict?\"\n",
    "context = \"Dependency conflicts occur when different packages require different versions of the same dependency.\"\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.5.1\n",
      "Uninstalling torch-2.5.1:\n",
      "  Successfully uninstalled torch-2.5.1\n",
      "Found existing installation: torchvision 0.21.0+cpu\n",
      "Uninstalling torchvision-0.21.0+cpu:\n",
      "  Successfully uninstalled torchvision-0.21.0+cpu\n",
      "Found existing installation: torchaudio 2.5.0\n",
      "Uninstalling torchaudio-2.5.0:\n",
      "  Successfully uninstalled torchaudio-2.5.0\n",
      "Found existing installation: xformers 0.0.20\n",
      "Uninstalling xformers-0.0.20:\n",
      "  Successfully uninstalled xformers-0.0.20\n",
      "Found existing installation: aiofiles 24.1.0\n",
      "Uninstalling aiofiles-24.1.0:\n",
      "  Successfully uninstalled aiofiles-24.1.0\n",
      "Found existing installation: MarkupSafe 3.0.2\n",
      "Uninstalling MarkupSafe-3.0.2:\n",
      "  Successfully uninstalled MarkupSafe-3.0.2\n",
      "Found existing installation: urllib3 1.26.18\n",
      "Uninstalling urllib3-1.26.18:\n",
      "  Successfully uninstalled urllib3-1.26.18\n",
      "Found existing installation: gradio 4.44.1\n",
      "Uninstalling gradio-4.44.1:\n",
      "  Successfully uninstalled gradio-4.44.1\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch==2.2.0\n",
      "  Using cached torch-2.2.0-cp39-cp39-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0) (2023.12.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.0)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.0)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.0)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.0)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.0)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.0)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.0)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.0)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.0)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch==2.2.0)\n",
      "  Using cached triton-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib64/python3.9/site-packages (from jinja2->torch==2.2.0) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from sympy->torch==2.2.0) (1.3.0)\n",
      "Downloading torch-2.2.0-cp39-cp39-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Using cached triton-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.1.0\n",
      "    Uninstalling triton-3.1.0:\n",
      "      Successfully uninstalled triton-3.1.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
      "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
      "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
      "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "facenet-pytorch 2.6.0 requires torchvision<0.18.0,>=0.17.0, which is not installed.\n",
      "sentence-transformers 2.2.2 requires torchvision, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.0 triton-2.2.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchvision==0.17.0\n",
      "  Downloading torchvision-0.17.0-cp39-cp39-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/.local/lib/python3.9/site-packages (from torchvision==0.17.0) (1.26.3)\n",
      "Requirement already satisfied: requests in /home/ec2-user/.local/lib/python3.9/site-packages (from torchvision==0.17.0) (2.32.3)\n",
      "Requirement already satisfied: torch==2.2.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from torchvision==0.17.0) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from torchvision==0.17.0) (10.2.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision==0.17.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision==0.17.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision==0.17.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision==0.17.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision==0.17.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision==0.17.0) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision==0.17.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision==0.17.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision==0.17.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision==0.17.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision==0.17.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision==0.17.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision==0.17.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision==0.17.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision==0.17.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision==0.17.0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision==0.17.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision==0.17.0) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->torchvision==0.17.0) (12.4.127)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->torchvision==0.17.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->torchvision==0.17.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.9/site-packages (from requests->torchvision==0.17.0) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->torchvision==0.17.0) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib64/python3.9/site-packages (from jinja2->torch==2.2.0->torchvision==0.17.0) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from sympy->torch==2.2.0->torchvision==0.17.0) (1.3.0)\n",
      "Downloading torchvision-0.17.0-cp39-cp39-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchvision\n",
      "Successfully installed torchvision-0.17.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: facenet-pytorch==2.6.0 in /home/ec2-user/.local/lib/python3.9/site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from facenet-pytorch==2.6.0) (1.26.3)\n",
      "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from facenet-pytorch==2.6.0) (10.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from facenet-pytorch==2.6.0) (2.32.3)\n",
      "Requirement already satisfied: torch<2.3.0,>=2.2.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from facenet-pytorch==2.6.0) (2.2.0)\n",
      "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from facenet-pytorch==2.6.0) (0.17.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from facenet-pytorch==2.6.0) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch==2.6.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch==2.6.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch==2.6.0) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch==2.6.0) (2023.11.17)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/.local/lib/python3.9/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/.local/lib/python3.9/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/.local/lib/python3.9/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/.local/lib/python3.9/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib64/python3.9/site-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch==2.6.0) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gradio==4.44.1\n",
      "  Using cached gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiofiles==23.1.0\n",
      "  Downloading aiofiles-23.1.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting markupsafe==2.1.1\n",
      "  Downloading MarkupSafe-2.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting urllib3==2.0.4\n",
      "  Downloading urllib3-2.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (4.8.0)\n",
      "Requirement already satisfied: fastapi<1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (0.115.8)\n",
      "Requirement already satisfied: ffmpy in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (1.3.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (0.29.3)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (6.4.5)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (3.1.2)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (3.7.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (1.26.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (3.10.15)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (2.2.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (10.2.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (2.10.6)\n",
      "Requirement already satisfied: pydub in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (0.9.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio==4.44.1) (0.34.0)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio-client==1.3.0->gradio==4.44.1) (2023.12.2)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from gradio-client==1.3.0->gradio==4.44.1) (12.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from anyio<5.0,>=3.0->gradio==4.44.1) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/.local/lib/python3.9/site-packages (from anyio<5.0,>=3.0->gradio==4.44.1) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from anyio<5.0,>=3.0->gradio==4.44.1) (1.3.1)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from fastapi<1.0->gradio==4.44.1) (0.45.3)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/.local/lib/python3.9/site-packages (from httpx>=0.24.1->gradio==4.44.1) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/.local/lib/python3.9/site-packages (from httpx>=0.24.1->gradio==4.44.1) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/.local/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio==4.44.1) (0.14.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/.local/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->gradio==4.44.1) (3.16.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/.local/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->gradio==4.44.1) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->gradio==4.44.1) (4.66.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from importlib-resources<7.0,>=1.3->gradio==4.44.1) (3.20.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio==4.44.1) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/.local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio==4.44.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio==4.44.1) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio==4.44.1) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio==4.44.1) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/.local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio==4.44.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas<3.0,>=1.0->gradio==4.44.1) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas<3.0,>=1.0->gradio==4.44.1) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from pydantic>=2.0->gradio==4.44.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from pydantic>=2.0->gradio==4.44.1) (2.27.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from typer<1.0,>=0.12->gradio==4.44.1) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from typer<1.0,>=0.12->gradio==4.44.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from typer<1.0,>=0.12->gradio==4.44.1) (13.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==4.44.1) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.44.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.44.1) (2.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->huggingface-hub>=0.19.3->gradio==4.44.1) (3.3.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==4.44.1) (0.1.2)\n",
      "Using cached gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
      "Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "Downloading MarkupSafe-2.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Downloading urllib3-2.0.4-py3-none-any.whl (123 kB)\n",
      "Installing collected packages: urllib3, markupsafe, aiofiles, gradio\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "botocore 1.37.18 requires urllib3<1.27,>=1.25.4; python_version < \"3.10\", but you have urllib3 2.0.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiofiles-23.1.0 gradio-4.44.1 markupsafe-2.1.1 urllib3-2.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y torch torchvision torchaudio xformers aiofiles markupsafe urllib3 gradio\n",
    "!pip install torch==2.2.0\n",
    "!pip install torchvision==0.17.0\n",
    "!pip install facenet-pytorch==2.6.0\n",
    "!pip install gradio==4.44.1 aiofiles==23.1.0 markupsafe==2.1.1 urllib3==2.0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 23:07:37.416815: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-23 23:07:37.921221: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742771258.108561   12686 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742771258.164793   12686 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-23 23:07:38.659088: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f336ff6164054e5f8311cd42473c3f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/598M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7deb1195c42e4247a6c59df0b75c4809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/21.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2d711f090e4322ad00cdc93b62217d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8904ad53ce42e48405112c3915b34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ 9.7704, -0.7821, -4.7557,  3.2676, -4.0456,  3.1307,  4.5291,  9.4809,\n",
      "          5.5877,  5.9925, 10.8607, 11.0336,  8.9084,  9.2726, 10.1642,  8.9332,\n",
      "          4.6125,  8.3634,  7.5077,  7.6692,  6.9890,  2.9429]],\n",
      "       grad_fn=<CloneBackward0>), end_logits=tensor([[ 9.1559, -0.5290, -0.2660,  1.9820, -1.3602,  3.3938,  4.8155,  6.6853,\n",
      "          6.7588,  5.6995,  2.7776,  2.5640,  5.8419,  5.5150,  5.5985,  9.5415,\n",
      "          5.1540,  5.0208,  8.4263, 12.6687, 11.1534,  0.6344]],\n",
      "       grad_fn=<CloneBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "\n",
    "model_name = \"Praise2112/ModernBERT-base-squad2-v0.2\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "question = \"What is dependency conflict?\"\n",
    "context = \"Dependency conflicts occur when different packages require different versions of the same dependency.\"\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# electra_large_discriminator_squad2_512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers==2.11.0\n",
      "  Downloading transformers-2.11.0-py3-none-any.whl.metadata (45 kB)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.5.0 (from versions: 1.7.1, 1.8.0, 1.8.1, 1.9.0, 1.9.1, 1.10.0, 1.10.1, 1.10.2, 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.5.0\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d6deb02e1042d788dfec3ea2703c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/475 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py\", line 1126, in _get_module\n",
      "    # Parse it and check the field \"sagemaker_distributed_dataparallel_enabled\".\n",
      "  File \"/usr/lib64/python3.9/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1030, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 984, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'transformers.models.ernie_m.configuration_ernie_m'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_13607/713093529.py\", line 6, in <module>\n",
      "    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 469, in from_pretrained\n",
      "    use_auth_token = hub_kwargs.pop(\"use_auth_token\", None)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 619, in keys\n",
      "    )\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 620, in <listcomp>\n",
      "    return super().from_config(config, **kwargs)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 616, in _load_attr_from_module\n",
      "    features_only=features_only,\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 561, in getattribute_from_module\n",
      "    )\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py\", line 1116, in __getattr__\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py\", line 1128, in _get_module\n",
      "    if not sagemaker_params.get(\"sagemaker_distributed_dataparallel_enabled\", False):\n",
      "RuntimeError: Failed to import transformers.models.ernie_m.configuration_ernie_m because of the following error (look up to see its traceback):\n",
      "No module named 'transformers.models.ernie_m.configuration_ernie_m'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==2.11.0 torch==1.5.0 tensorflow==2.2.0\n",
    "\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "\n",
    "model_name = \"ahotrod/electra_large_discriminator_squad2_512\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "question = \"Explain version conflicts in dependency management.\"\n",
    "context = \"Version conflicts can cause errors during package installation or runtime execution.\"\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers==2.11.0\n",
      "  Using cached transformers-2.11.0-py3-none-any.whl (674 kB)\n",
      "Collecting torch==1.7.1\n",
      "  Using cached torch-1.7.1-cp39-cp39-manylinux1_x86_64.whl (776.8 MB)\n",
      "Collecting tensorflow==2.5.0\n",
      "  Downloading tensorflow-2.5.0-cp39-cp39-manylinux2010_x86_64.whl (454.4 MB)\n",
      "     || 454.4 MB 16 kB/s               \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==2.11.0) (4.67.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==2.11.0) (3.16.1)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==2.11.0) (0.1.1)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==2.11.0) (24.1)\n",
      "Collecting tokenizers==0.7.0\n",
      "  Downloading tokenizers-0.7.0.tar.gz (81 kB)\n",
      "     || 81 kB 17.9 MB/s            \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==2.11.0) (2.32.3)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==2.11.0) (1.26.3)\n",
      "Requirement already satisfied: sentencepiece in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==2.11.0) (0.1.99)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==2.11.0) (2024.11.6)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==1.7.1) (4.12.2)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "     || 132 kB 70.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from tensorflow==2.5.0) (4.25.6)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "     || 1.2 MB 53.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /home/ec2-user/.local/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.6.3)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp39-cp39-manylinux2014_x86_64.whl (4.0 MB)\n",
      "     || 4.0 MB 113.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /home/ec2-user/.local/lib/python3.9/site-packages (from tensorflow==2.5.0) (0.45.1)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     || 65 kB 3.8 MB/s             \n",
      "\u001b[?25hCollecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting typing-extensions\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     || 42 kB 3.1 MB/s              \n",
      "\u001b[?25hCollecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "     || 462 kB 120.2 MB/s            \n",
      "\u001b[?25hCollecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numpy\n",
      "  Using cached numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from tensorflow==2.5.0) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from tensorflow==2.5.0) (2.19.0)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n",
      "     || 4.4 MB 97.6 MB/s            \n",
      "\u001b[?25hCollecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (75.8.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.0.1)\n",
      "Collecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "     || 5.5 MB 119.3 MB/s            \n",
      "\u001b[?25h  Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "     || 5.5 MB 127.2 MB/s            \n",
      "\u001b[?25h  Downloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
      "     || 5.5 MB 71.0 MB/s            \n",
      "\u001b[?25h  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "     || 5.5 MB 122.4 MB/s            \n",
      "\u001b[?25h  Downloading tensorboard-2.16.1-py3-none-any.whl (5.5 MB)\n",
      "     || 5.5 MB 52.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tf-keras>=2.15.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.18.0)\n",
      "  Downloading tensorboard-2.16.0-py3-none-any.whl (5.5 MB)\n",
      "     || 5.5 MB 128.0 MB/s            \n",
      "\u001b[?25hCollecting tf-keras-nightly\n",
      "  Downloading tf_keras_nightly-2.20.0.dev2025032309-py3-none-any.whl (1.7 MB)\n",
      "     || 1.7 MB 107.2 MB/s            \n",
      "\u001b[?25hCollecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "     || 5.5 MB 100.3 MB/s            \n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "     || 210 kB 108.4 MB/s            \n",
      "\u001b[?25hCollecting google-auth-oauthlib<2,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.2.1-py2.py3-none-any.whl (24 kB)\n",
      "Collecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "     || 5.5 MB 98.8 MB/s            \n",
      "\u001b[?25hCollecting protobuf>=3.9.2\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "     || 304 kB 110.0 MB/s            \n",
      "\u001b[?25hCollecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.15.0-py3-none-any.whl (5.6 MB)\n",
      "     || 5.6 MB 61.6 MB/s            \n",
      "\u001b[?25h  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "     || 5.5 MB 132.1 MB/s            \n",
      "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.14.0-py3-none-any.whl (5.5 MB)\n",
      "     || 5.5 MB 133.7 MB/s            \n",
      "\u001b[?25h  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "     || 5.6 MB 118.3 MB/s            \n",
      "\u001b[?25h  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "     || 5.6 MB 110.3 MB/s            \n",
      "\u001b[?25h  Downloading tensorboard-2.12.2-py3-none-any.whl (5.6 MB)\n",
      "     || 5.6 MB 99.0 MB/s            \n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     || 781 kB 90.4 MB/s            \n",
      "\u001b[?25hCollecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.12.1-py3-none-any.whl (5.6 MB)\n",
      "     || 5.6 MB 68.1 MB/s            \n",
      "\u001b[?25h  Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n",
      "     || 5.6 MB 20.3 MB/s            \n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "     || 6.0 MB 73.6 MB/s            \n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "     || 4.9 MB 111.4 MB/s            \n",
      "\u001b[?25hCollecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "     || 1.0 MB 111.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /home/ec2-user/.local/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==2.11.0) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==2.11.0) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==2.11.0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.9/site-packages (from requests->transformers==2.11.0) (1.25.10)\n",
      "Requirement already satisfied: click in /home/ec2-user/.local/lib/python3.9/site-packages (from sacremoses->transformers==2.11.0) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/.local/lib/python3.9/site-packages (from sacremoses->transformers==2.11.0) (1.3.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (5.5.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ec2-user/.local/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (7.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib64/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow==2.5.0) (3.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/ec2-user/.local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.0.2)\n",
      "Building wheels for collected packages: tokenizers, termcolor, wrapt\n",
      "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /usr/bin/python3 /usr/lib/python3.9/site-packages/pip/_vendor/pep517/in_process/_in_process.py build_wheel /tmp/tmplvxpmof8\n",
      "       cwd: /tmp/pip-install-br5vew9m/tokenizers_440c40e9ccd942fc84454887fc456a1d\n",
      "  Complete output (57 lines):\n",
      "  /tmp/pip-build-env-b7qilwne/overlay/lib/python3.9/site-packages/setuptools/dist.py:760: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \n",
      "          License :: OSI Approved :: Apache Software License\n",
      "  \n",
      "          See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    self._finalize_license_expression()\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build/lib.linux-x86_64-cpython-39/tokenizers\n",
      "  copying tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-39/tokenizers\n",
      "  creating build/lib.linux-x86_64-cpython-39/tokenizers/models\n",
      "  copying tokenizers/models/__init__.py -> build/lib.linux-x86_64-cpython-39/tokenizers/models\n",
      "  creating build/lib.linux-x86_64-cpython-39/tokenizers/decoders\n",
      "  copying tokenizers/decoders/__init__.py -> build/lib.linux-x86_64-cpython-39/tokenizers/decoders\n",
      "  creating build/lib.linux-x86_64-cpython-39/tokenizers/normalizers\n",
      "  copying tokenizers/normalizers/__init__.py -> build/lib.linux-x86_64-cpython-39/tokenizers/normalizers\n",
      "  creating build/lib.linux-x86_64-cpython-39/tokenizers/pre_tokenizers\n",
      "  copying tokenizers/pre_tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-39/tokenizers/pre_tokenizers\n",
      "  creating build/lib.linux-x86_64-cpython-39/tokenizers/processors\n",
      "  copying tokenizers/processors/__init__.py -> build/lib.linux-x86_64-cpython-39/tokenizers/processors\n",
      "  creating build/lib.linux-x86_64-cpython-39/tokenizers/trainers\n",
      "  copying tokenizers/trainers/__init__.py -> build/lib.linux-x86_64-cpython-39/tokenizers/trainers\n",
      "  creating build/lib.linux-x86_64-cpython-39/tokenizers/implementations\n",
      "  copying tokenizers/implementations/sentencepiece_bpe.py -> build/lib.linux-x86_64-cpython-39/tokenizers/implementations\n",
      "  copying tokenizers/implementations/char_level_bpe.py -> build/lib.linux-x86_64-cpython-39/tokenizers/implementations\n",
      "  copying tokenizers/implementations/byte_level_bpe.py -> build/lib.linux-x86_64-cpython-39/tokenizers/implementations\n",
      "  copying tokenizers/implementations/bert_wordpiece.py -> build/lib.linux-x86_64-cpython-39/tokenizers/implementations\n",
      "  copying tokenizers/implementations/base_tokenizer.py -> build/lib.linux-x86_64-cpython-39/tokenizers/implementations\n",
      "  copying tokenizers/implementations/__init__.py -> build/lib.linux-x86_64-cpython-39/tokenizers/implementations\n",
      "  copying tokenizers/__init__.pyi -> build/lib.linux-x86_64-cpython-39/tokenizers\n",
      "  copying tokenizers/models/__init__.pyi -> build/lib.linux-x86_64-cpython-39/tokenizers/models\n",
      "  copying tokenizers/decoders/__init__.pyi -> build/lib.linux-x86_64-cpython-39/tokenizers/decoders\n",
      "  copying tokenizers/normalizers/__init__.pyi -> build/lib.linux-x86_64-cpython-39/tokenizers/normalizers\n",
      "  copying tokenizers/pre_tokenizers/__init__.pyi -> build/lib.linux-x86_64-cpython-39/tokenizers/pre_tokenizers\n",
      "  copying tokenizers/processors/__init__.pyi -> build/lib.linux-x86_64-cpython-39/tokenizers/processors\n",
      "  copying tokenizers/trainers/__init__.pyi -> build/lib.linux-x86_64-cpython-39/tokenizers/trainers\n",
      "  running build_ext\n",
      "  running build_rust\n",
      "  error: can't find Rust compiler\n",
      "  \n",
      "  If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \n",
      "  To update pip, run:\n",
      "  \n",
      "      pip install --upgrade pip\n",
      "  \n",
      "  and then retry package installation.\n",
      "  \n",
      "  If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4872 sha256=84a3615ec8d1ef8becd4c4110cb2d8a8cf1bd1f4669114a054366e6fb0733bff\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-py3-none-any.whl size=19595 sha256=6f5409472170a758985c74f6b216b1f8fc425d5d406a27e6c27b696b43c082e2\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/98/23/68/efe259aaca055e93b08e74fbe512819c69a2155c11ba3c0f10\n",
      "Successfully built termcolor wrapt\n",
      "Failed to build tokenizers\n",
      "\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y torch \n",
    "!pip install transformers==2.11.0 torch==1.7.1 tensorflow==2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da021557c66d47fd9720d6f697399923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/475 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.lxmert.configuration_lxmert because of the following error (look up to see its traceback):\nNo module named 'transformers.models.lxmert.configuration_lxmert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/file_utils.py:2150\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib64/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:984\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers.models.lxmert.configuration_lxmert'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForQuestionAnswering, AutoTokenizer\n\u001b[1;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mahotrod/electra_large_discriminator_squad2_512\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForQuestionAnswering\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m      7\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplain version conflicts in dependency management.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:417\u001b[0m, in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:548\u001b[0m, in \u001b[0;36mkeys\u001b[0;34m(self)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:549\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:545\u001b[0m, in \u001b[0;36m_load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:507\u001b[0m, in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/file_utils.py:2140\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2138\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   2139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 2140\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2141\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   2142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/file_utils.py:2152\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2153\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2154\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.lxmert.configuration_lxmert because of the following error (look up to see its traceback):\nNo module named 'transformers.models.lxmert.configuration_lxmert'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "\n",
    "model_name = \"ahotrod/electra_large_discriminator_squad2_512\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "question = \"Explain version conflicts in dependency management.\"\n",
    "context = \"Version conflicts can cause errors during package installation or runtime execution.\"\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers==4.7.0\n",
      "  Downloading transformers-4.7.0-py3-none-any.whl.metadata (48 kB)\n",
      "Collecting torch==1.8.0\n",
      "  Using cached torch-1.8.0-cp39-cp39-manylinux1_x86_64.whl.metadata (23 kB)\n",
      "Collecting datasets==1.4.1\n",
      "  Downloading datasets-1.4.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting tokenizers==0.10.2\n",
      "  Downloading tokenizers-0.10.2-cp39-cp39-manylinux2010_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.7.0) (3.16.1)\n",
      "Collecting huggingface-hub==0.0.8 (from transformers==4.7.0)\n",
      "  Downloading huggingface_hub-0.0.8-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.7.0) (1.26.3)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.7.0) (24.1)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.7.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.7.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.7.0) (2.32.3)\n",
      "Collecting sacremoses (from transformers==4.7.0)\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.7.0) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==1.8.0) (4.12.2)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.4.1) (19.0.1)\n",
      "Requirement already satisfied: dill in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.4.1) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.4.1) (2.2.2)\n",
      "Collecting tqdm>=4.27 (from transformers==4.7.0)\n",
      "  Downloading tqdm-4.49.0-py2.py3-none-any.whl.metadata (55 kB)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.4.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.4.1) (0.70.15)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.4.1) (2023.12.2)\n",
      "INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Cannot install datasets==1.4.1 and transformers==4.7.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "The conflict is caused by:\n",
      "    transformers 4.7.0 depends on huggingface-hub==0.0.8\n",
      "    datasets 1.4.1 depends on huggingface-hub==0.0.2\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
      "\n",
      "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4002016fca4717856fae8d00859058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py\", line 1126, in _get_module\n",
      "    # Parse it and check the field \"sagemaker_distributed_dataparallel_enabled\".\n",
      "  File \"/usr/lib64/python3.9/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1030, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 984, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'transformers.models.ernie_m.configuration_ernie_m'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_13607/328999849.py\", line 7, in <module>\n",
      "    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 469, in from_pretrained\n",
      "    use_auth_token = hub_kwargs.pop(\"use_auth_token\", None)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 619, in keys\n",
      "    )\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 620, in <listcomp>\n",
      "    return super().from_config(config, **kwargs)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 616, in _load_attr_from_module\n",
      "    features_only=features_only,\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 561, in getattribute_from_module\n",
      "    )\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py\", line 1116, in __getattr__\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py\", line 1128, in _get_module\n",
      "    if not sagemaker_params.get(\"sagemaker_distributed_dataparallel_enabled\", False):\n",
      "RuntimeError: Failed to import transformers.models.ernie_m.configuration_ernie_m because of the following error (look up to see its traceback):\n",
      "No module named 'transformers.models.ernie_m.configuration_ernie_m'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# Code Block 3: bigwiz83/sapbert-from-pubmedbert-squad2\n",
    "!pip install transformers==4.7.0 torch==1.8.0 datasets==1.4.1 tokenizers==0.10.2\n",
    "\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "\n",
    "model_name = \"bigwiz83/sapbert-from-pubmedbert-squad2\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "question = \"What issues arise from dependency conflicts?\"\n",
    "context = \"When multiple libraries require conflicting versions, errors are likely to happen.\"\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.48.0\n",
      "Uninstalling transformers-4.48.0:\n",
      "  Successfully uninstalled transformers-4.48.0\n",
      "Found existing installation: datasets 2.20.0\n",
      "Uninstalling datasets-2.20.0:\n",
      "  Successfully uninstalled datasets-2.20.0\n",
      "Found existing installation: huggingface-hub 0.29.3\n",
      "Uninstalling huggingface-hub-0.29.3:\n",
      "  Successfully uninstalled huggingface-hub-0.29.3\n",
      "Found existing installation: tokenizers 0.21.0\n",
      "Uninstalling tokenizers-0.21.0:\n",
      "  Successfully uninstalled tokenizers-0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers==4.7.0\n",
      "  Using cached transformers-4.7.0-py3-none-any.whl.metadata (48 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.7.0) (3.16.1)\n",
      "Collecting huggingface-hub==0.0.8 (from transformers==4.7.0)\n",
      "  Using cached huggingface_hub-0.0.8-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.7.0) (1.26.3)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.7.0) (24.1)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.7.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.7.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.7.0) (2.32.3)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.7.0) (0.1.1)\n",
      "Collecting tokenizers<0.11,>=0.10.1 (from transformers==4.7.0)\n",
      "  Using cached tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.7.0) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.7.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.7.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.7.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.7.0) (2023.11.17)\n",
      "Requirement already satisfied: click in /home/ec2-user/.local/lib/python3.9/site-packages (from sacremoses->transformers==4.7.0) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/.local/lib/python3.9/site-packages (from sacremoses->transformers==4.7.0) (1.3.2)\n",
      "Downloading transformers-4.7.0-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
      "Using cached tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "evaluate 0.4.3 requires datasets>=2.0.0, which is not installed.\n",
      "diffusers 0.32.2 requires huggingface-hub>=0.23.2, but you have huggingface-hub 0.0.8 which is incompatible.\n",
      "evaluate 0.4.3 requires huggingface-hub>=0.7.0, but you have huggingface-hub 0.0.8 which is incompatible.\n",
      "gradio 4.44.1 requires huggingface-hub>=0.19.3, but you have huggingface-hub 0.0.8 which is incompatible.\n",
      "gradio-client 1.3.0 requires huggingface-hub>=0.19.3, but you have huggingface-hub 0.0.8 which is incompatible.\n",
      "peft 0.9.0 requires huggingface-hub>=0.17.0, but you have huggingface-hub 0.0.8 which is incompatible.\n",
      "sentence-transformers 2.2.2 requires huggingface-hub>=0.4.0, but you have huggingface-hub 0.0.8 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.0.8 tokenizers-0.10.3 transformers-4.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting datasets==1.6.0\n",
      "  Downloading datasets-1.6.0-py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.6.0) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=1.0.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.6.0) (19.0.1)\n",
      "Requirement already satisfied: dill in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.6.0) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.6.0) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.6.0) (2.32.3)\n",
      "Collecting tqdm<4.50.0,>=4.27 (from datasets==1.6.0)\n",
      "  Using cached tqdm-4.49.0-py2.py3-none-any.whl.metadata (55 kB)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.6.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.6.0) (0.70.14)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.6.0) (2023.12.2)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.6.0) (0.0.8)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.6.0) (24.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/.local/lib/python3.9/site-packages (from huggingface-hub<0.1.0->datasets==1.6.0) (3.16.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.6.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.6.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.6.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.6.0) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas->datasets==1.6.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas->datasets==1.6.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas->datasets==1.6.0) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets==1.6.0) (1.16.0)\n",
      "Downloading datasets-1.6.0-py3-none-any.whl (202 kB)\n",
      "Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n",
      "Installing collected packages: tqdm, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.5\n",
      "    Uninstalling tqdm-4.66.5:\n",
      "      Successfully uninstalled tqdm-4.66.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "evaluate 0.4.3 requires datasets>=2.0.0, but you have datasets 1.6.0 which is incompatible.\n",
      "evaluate 0.4.3 requires huggingface-hub>=0.7.0, but you have huggingface-hub 0.0.8 which is incompatible.\n",
      "evaluate 0.4.3 requires tqdm>=4.62.1, but you have tqdm 4.49.0 which is incompatible.\n",
      "peft 0.9.0 requires huggingface-hub>=0.17.0, but you have huggingface-hub 0.0.8 which is incompatible.\n",
      "sentence-transformers 2.2.2 requires huggingface-hub>=0.4.0, but you have huggingface-hub 0.0.8 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-1.6.0 tqdm-4.49.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tokenizers==0.10.2\n",
      "  Using cached tokenizers-0.10.2-cp39-cp39-manylinux2010_x86_64.whl.metadata (5.8 kB)\n",
      "Downloading tokenizers-0.10.2-cp39-cp39-manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.10.3\n",
      "    Uninstalling tokenizers-0.10.3:\n",
      "      Successfully uninstalled tokenizers-0.10.3\n",
      "Successfully installed tokenizers-0.10.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /home/ec2-user/.local/lib/python3.9/site-packages (0.0.8)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/.local/lib/python3.9/site-packages (from huggingface-hub==0.0.8) (3.16.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/.local/lib/python3.9/site-packages (from huggingface-hub==0.0.8) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/.local/lib/python3.9/site-packages (from huggingface-hub==0.0.8) (4.49.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->huggingface-hub==0.0.8) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->huggingface-hub==0.0.8) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->huggingface-hub==0.0.8) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->huggingface-hub==0.0.8) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y transformers datasets huggingface-hub tokenizers\n",
    "!pip install transformers==4.7.0\n",
    "!pip install datasets==1.6.0\n",
    "!pip install tokenizers==0.10.2\n",
    "!pip install huggingface-hub==0.0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0a8a0f03424013aa280ef2aa4e61ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=642.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0c8101d36d462ead2ccdf4d42c1c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435660911.0, style=ProgressStyle(descri"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b2f24a10bd49d6914c5aa66d8a4377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=226150.0, style=ProgressStyle(descripti"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f3b3a8c69e4658b2afaaab000b2366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=460875.0, style=ProgressStyle(descripti"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457b3e6c78654099864ec98041a4acc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a9f9acd4c945918353c6c4e1dc967d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=365.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ 1.1368, -4.9146, -5.2487, -7.3861, -7.6255, -5.4474, -7.0285, -8.2898,\n",
      "         -7.5452,  0.1335,  0.8179, -0.4820, -2.7206, -0.5917, -0.9558, -0.1014,\n",
      "          6.7624, -2.4672, -0.1479, -4.4067, -1.0293, -0.7967, -4.7433]],\n",
      "       grad_fn=<CloneBackward0>), end_logits=tensor([[ 1.8309, -5.8596, -4.3662, -8.0650, -8.4170, -6.2748, -6.0801, -7.8794,\n",
      "         -6.3227, -6.1576, -3.7363, -0.5591, -4.0226, -2.5224,  1.2005, -0.4061,\n",
      "          5.9079, -1.4456,  2.0518, -2.9552,  5.7826,  6.1044, -2.8787]],\n",
      "       grad_fn=<CloneBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "\n",
    "model_name = \"bigwiz83/sapbert-from-pubmedbert-squad2\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "question = \"What issues arise from dependency conflicts?\"\n",
    "context = \"When multiple libraries require conflicting versions, errors are likely to happen.\"\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers==4.12.5\n",
      "  Using cached transformers-4.12.5-py3-none-any.whl.metadata (56 kB)\n",
      "Collecting torch==1.10.0\n",
      "  Downloading torch-1.10.0-cp39-cp39-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Collecting datasets==1.15.1\n",
      "  Downloading datasets-1.15.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting tokenizers==0.10.3\n",
      "  Downloading tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.12.5) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.12.5) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.12.5) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.12.5) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.12.5) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.12.5) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.12.5) (2.32.3)\n",
      "Collecting sacremoses (from transformers==4.12.5)\n",
      "  Using cached sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.12.5) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==1.10.0) (4.12.2)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.15.1) (19.0.1)\n",
      "Requirement already satisfied: dill in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.15.1) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.15.1) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.15.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.15.1) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from fsspec[http]>=2021.05.0->datasets==1.15.1) (2023.12.2)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.15.1) (3.9.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==1.15.1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==1.15.1) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==1.15.1) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==1.15.1) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==1.15.1) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==1.15.1) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.12.5) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.12.5) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.12.5) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.12.5) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas->datasets==1.15.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas->datasets==1.15.1) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas->datasets==1.15.1) (2024.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/.local/lib/python3.9/site-packages (from sacremoses->transformers==4.12.5) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/.local/lib/python3.9/site-packages (from sacremoses->transformers==4.12.5) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets==1.15.1) (1.16.0)\n",
      "Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-1.10.0-cp39-cp39-manylinux1_x86_64.whl (881.9 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m881.9/881.9 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-1.15.1-py3-none-any.whl (290 kB)\n",
      "Downloading tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, torch, sacremoses, transformers, datasets\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.0\n",
      "    Uninstalling tokenizers-0.21.0:\n",
      "      Successfully uninstalled tokenizers-0.21.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1\n",
      "    Uninstalling torch-2.5.1:\n",
      "      Successfully uninstalled torch-2.5.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.48.0\n",
      "    Uninstalling transformers-4.48.0:\n",
      "      Successfully uninstalled transformers-4.48.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.20.0\n",
      "    Uninstalling datasets-2.20.0:\n",
      "      Successfully uninstalled datasets-2.20.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "evaluate 0.4.3 requires datasets>=2.0.0, but you have datasets 1.15.1 which is incompatible.\n",
      "facenet-pytorch 2.6.0 requires torch<2.3.0,>=2.2.0, but you have torch 1.10.0 which is incompatible.\n",
      "facenet-pytorch 2.6.0 requires torchvision<0.18.0,>=0.17.0, but you have torchvision 0.21.0+cpu which is incompatible.\n",
      "peft 0.9.0 requires torch>=1.13.0, but you have torch 1.10.0 which is incompatible.\n",
      "torchaudio 2.5.0 requires torch==2.5.0, but you have torch 1.10.0 which is incompatible.\n",
      "torchvision 0.21.0+cpu requires torch==2.6.0, but you have torch 1.10.0 which is incompatible.\n",
      "xformers 0.0.20 requires torch==2.0.1, but you have torch 1.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-1.15.1 sacremoses-0.1.1 tokenizers-0.10.3 torch-1.10.0 transformers-4.12.5\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py\", line 1126, in _get_module\n",
      "  File \"/usr/lib64/python3.9/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1030, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 984, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'transformers.models.ernie_m.configuration_ernie_m'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_13607/1299212770.py\", line 7, in <module>\n",
      "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 469, in from_pretrained\n",
      "    from_config.__doc__ = from_config_docstring\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 619, in keys\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 620, in <listcomp>\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 616, in _load_attr_from_module\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 561, in getattribute_from_module\n",
      "    def __bool__(self):\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py\", line 1116, in __getattr__\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py\", line 1128, in _get_module\n",
      "RuntimeError: Failed to import transformers.models.ernie_m.configuration_ernie_m because of the following error (look up to see its traceback):\n",
      "No module named 'transformers.models.ernie_m.configuration_ernie_m'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# Code Block 4: papluca/xlm-roberta-base-language-detection\n",
    "!pip install transformers==4.12.5 torch==1.10.0 datasets==1.15.1 tokenizers==0.10.3\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"papluca/xlm-roberta-base-language-detection\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "text = \"This is a test sentence.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: evaluate 0.4.3\n",
      "Uninstalling evaluate-0.4.3:\n",
      "  Successfully uninstalled evaluate-0.4.3\n",
      "\u001b[33mWARNING: Skipping facenet-pytorch as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: peft 0.9.0\n",
      "Uninstalling peft-0.9.0:\n",
      "  Successfully uninstalled peft-0.9.0\n",
      "\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: torchvision 0.16.0\n",
      "Uninstalling torchvision-0.16.0:\n",
      "  Successfully uninstalled torchvision-0.16.0\n",
      "\u001b[33mWARNING: Skipping xformers as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers==4.12.5\n",
      "  Using cached transformers-4.12.5-py3-none-any.whl.metadata (56 kB)\n",
      "Collecting torch==1.10.0\n",
      "  Using cached torch-1.10.0-cp39-cp39-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Collecting datasets==1.15.1\n",
      "  Using cached datasets-1.15.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting tokenizers==0.10.3\n",
      "  Using cached tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.12.5) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.12.5) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.12.5) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.12.5) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.12.5) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.12.5) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.12.5) (2.32.3)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.12.5) (0.1.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.12.5) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==1.10.0) (4.12.2)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.15.1) (19.0.1)\n",
      "Requirement already satisfied: dill in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.15.1) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.15.1) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.15.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.15.1) (0.70.14)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from fsspec[http]>=2021.05.0->datasets==1.15.1) (2023.12.2)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==1.15.1) (3.9.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==1.15.1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==1.15.1) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==1.15.1) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==1.15.1) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==1.15.1) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==1.15.1) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.12.5) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.12.5) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.9/site-packages (from requests->transformers==4.12.5) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.12.5) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas->datasets==1.15.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas->datasets==1.15.1) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas->datasets==1.15.1) (2024.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/.local/lib/python3.9/site-packages (from sacremoses->transformers==4.12.5) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/.local/lib/python3.9/site-packages (from sacremoses->transformers==4.12.5) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets==1.15.1) (1.16.0)\n",
      "Using cached transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
      "Using cached torch-1.10.0-cp39-cp39-manylinux1_x86_64.whl (881.9 MB)\n",
      "Using cached datasets-1.15.1-py3-none-any.whl (290 kB)\n",
      "Using cached tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "Installing collected packages: tokenizers, torch, transformers, datasets\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.14.1\n",
      "    Uninstalling tokenizers-0.14.1:\n",
      "      Successfully uninstalled tokenizers-0.14.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0\n",
      "    Uninstalling torch-2.1.0:\n",
      "      Successfully uninstalled torch-2.1.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.16.2\n",
      "    Uninstalling transformers-4.16.2:\n",
      "      Successfully uninstalled transformers-4.16.2\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.9.0\n",
      "    Uninstalling datasets-2.9.0:\n",
      "      Successfully uninstalled datasets-2.9.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sentence-transformers 2.2.2 requires torchvision, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-1.15.1 tokenizers-0.10.3 torch-1.10.0 transformers-4.12.5\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y evaluate facenet-pytorch peft torchaudio torchvision xformers \n",
    "!pip install transformers==4.12.5 torch==1.10.0 datasets==1.15.1 tokenizers==0.10.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 01:08:56.393502: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-24 01:08:56.410381: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742778536.430523   16690 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742778536.436499   16690 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-24 01:08:56.459213: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3b06bac23942a8be1947903b930116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5bb892315145e8b12af67d8a266551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823c756e1a1542a5a12a0d471a56d45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3140c7b7fda741fd9a7fa97340ea14e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65b404341674ded8b0f91a102194b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/8.66M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fad3f7c1fd4d5aa04e033677d0739d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-0.9294,  0.2665, -1.2123, -0.6366, -0.4184, -0.1648, -0.4607,  0.2771,\n",
      "         -0.0657, -0.9682,  0.2180,  0.5397, -0.5279,  7.0440, -0.4062, -1.3086,\n",
      "         -0.0667, -0.5790,  0.1626, -0.0940]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"papluca/xlm-roberta-base-language-detection\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "text = \"This is a test sentence.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers==4.16.2\n",
      "  Using cached transformers-4.16.2-py3-none-any.whl.metadata (61 kB)\n",
      "Collecting torch==2.1.0\n",
      "  Using cached torch-2.1.0-cp39-cp39-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting datasets==2.9.0\n",
      "  Downloading datasets-2.9.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting tokenizers==0.14.1\n",
      "  Downloading tokenizers-0.14.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.16.2) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.16.2) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.16.2) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.16.2) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.16.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.16.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.16.2) (2.32.3)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.16.2) (0.1.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.16.2) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (2023.12.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.0)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.0)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.0)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.0)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.0)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.0)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.0)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.0)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.0)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0)\n",
      "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.0)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.1.0 (from torch==2.1.0)\n",
      "  Downloading triton-2.1.0-0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==2.9.0) (19.0.1)\n",
      "Collecting dill<0.3.7 (from datasets==2.9.0)\n",
      "  Downloading dill-0.3.6-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==2.9.0) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==2.9.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==2.9.0) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==2.9.0) (3.9.3)\n",
      "Collecting responses<0.19 (from datasets==2.9.0)\n",
      "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0 (from transformers==4.16.2)\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0) (12.4.127)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.9.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.9.0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.9.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.9.0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.9.0) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.9.0) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.16.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.16.2) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.16.2) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.16.2) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from jinja2->torch==2.1.0) (3.0.2)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets==2.9.0)\n",
      "  Using cached multiprocess-0.70.17-py39-none-any.whl.metadata (7.2 kB)\n",
      "  Using cached multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading multiprocess-0.70.14-py39-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas->datasets==2.9.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas->datasets==2.9.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas->datasets==2.9.0) (2024.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/.local/lib/python3.9/site-packages (from sacremoses->transformers==4.16.2) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/.local/lib/python3.9/site-packages (from sacremoses->transformers==4.16.2) (1.3.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from sympy->torch==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.9.0) (1.16.0)\n",
      "Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.0-cp39-cp39-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
      "Downloading tokenizers-0.14.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m133.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m126.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Downloading triton-2.1.0-0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m89.3/89.3 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, responses, nvidia-cusolver-cu12, nvidia-cudnn-cu12, multiprocess, huggingface-hub, torch, tokenizers, transformers, datasets\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.1.0\n",
      "    Uninstalling triton-3.1.0:\n",
      "      Successfully uninstalled triton-3.1.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
      "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
      "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
      "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.7\n",
      "    Uninstalling dill-0.3.7:\n",
      "      Successfully uninstalled dill-0.3.7\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.15\n",
      "    Uninstalling multiprocess-0.70.15:\n",
      "      Successfully uninstalled multiprocess-0.70.15\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.28.1\n",
      "    Uninstalling huggingface-hub-0.28.1:\n",
      "      Successfully uninstalled huggingface-hub-0.28.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.10.0\n",
      "    Uninstalling torch-1.10.0:\n",
      "      Successfully uninstalled torch-1.10.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.10.3\n",
      "    Uninstalling tokenizers-0.10.3:\n",
      "      Successfully uninstalled tokenizers-0.10.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.12.5\n",
      "    Uninstalling transformers-4.12.5:\n",
      "      Successfully uninstalled transformers-4.12.5\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 1.15.1\n",
      "    Uninstalling datasets-1.15.1:\n",
      "      Successfully uninstalled datasets-1.15.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "diffusers 0.32.2 requires huggingface-hub>=0.23.2, but you have huggingface-hub 0.17.3 which is incompatible.\n",
      "facenet-pytorch 2.6.0 requires torch<2.3.0,>=2.2.0, but you have torch 2.1.0 which is incompatible.\n",
      "facenet-pytorch 2.6.0 requires torchvision<0.18.0,>=0.17.0, but you have torchvision 0.21.0+cpu which is incompatible.\n",
      "gradio 4.44.1 requires aiofiles<24.0,>=22.0, but you have aiofiles 24.1.0 which is incompatible.\n",
      "gradio 4.44.1 requires huggingface-hub>=0.19.3, but you have huggingface-hub 0.17.3 which is incompatible.\n",
      "gradio 4.44.1 requires markupsafe~=2.0, but you have markupsafe 3.0.2 which is incompatible.\n",
      "gradio 4.44.1 requires urllib3~=2.0, but you have urllib3 1.26.18 which is incompatible.\n",
      "gradio-client 1.3.0 requires huggingface-hub>=0.19.3, but you have huggingface-hub 0.17.3 which is incompatible.\n",
      "torchaudio 2.5.0 requires torch==2.5.0, but you have torch 2.1.0 which is incompatible.\n",
      "torchvision 0.21.0+cpu requires torch==2.6.0, but you have torch 2.1.0 which is incompatible.\n",
      "xformers 0.0.20 requires torch==2.0.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-2.9.0 dill-0.3.6 huggingface-hub-0.17.3 multiprocess-0.70.14 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 responses-0.18.0 tokenizers-0.14.1 torch-2.1.0 transformers-4.16.2 triton-2.1.0\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py\", line 1126, in _get_module\n",
      "  File \"/usr/lib64/python3.9/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1030, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 984, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'transformers.models.ernie_m.configuration_ernie_m'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_13607/3975985701.py\", line 7, in <module>\n",
      "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 469, in from_pretrained\n",
      "    )\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 619, in keys\n",
      "    model_type = self._reverse_config_mapping[item.__name__]\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 620, in <listcomp>\n",
      "    return model_type in self._model_mapping\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 616, in _load_attr_from_module\n",
      "    return True\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 561, in getattribute_from_module\n",
      "    if key in self._extra_content:\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py\", line 1116, in __getattr__\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py\", line 1128, in _get_module\n",
      "RuntimeError: Failed to import transformers.models.ernie_m.configuration_ernie_m because of the following error (look up to see its traceback):\n",
      "No module named 'transformers.models.ernie_m.configuration_ernie_m'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# Code Block 5: TieIncred/distilbert-base-uncased-finetuned-emotional\n",
    "!pip install transformers==4.16.2 torch==2.1.0 datasets==2.9.0 tokenizers==0.14.1\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"TieIncred/distilbert-base-uncased-finetuned-emotional\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "text = \"I feel great about dependency conflict experiments!\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33mWARNING: Skipping diffusers as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping facenet-pytorch as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping gradio as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping gradio-client as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping xformers as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping aiofiles as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: MarkupSafe 3.0.2\n",
      "Uninstalling MarkupSafe-3.0.2:\n",
      "\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.9/shutil.py\", line 825, in move\n",
      "    os.rename(src, real_dst)\n",
      "OSError: [Errno 18] Invalid cross-device link: '/usr/local/lib64/python3.9/site-packages/MarkupSafe-3.0.2.dist-info/' -> '/tmp/pip-uninstall-5wwwsd3c'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/pip/_internal/cli/base_command.py\", line 106, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/pip/_internal/cli/base_command.py\", line 97, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/pip/_internal/commands/uninstall.py\", line 106, in run\n",
      "    uninstall_pathset = req.uninstall(\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/pip/_internal/req/req_install.py\", line 723, in uninstall\n",
      "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/pip/_internal/req/req_uninstall.py\", line 370, in remove\n",
      "    moved.stash(path)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/pip/_internal/req/req_uninstall.py\", line 261, in stash\n",
      "    renames(path, new_path)\n",
      "  File \"/home/ec2-user/.local/lib/python3.9/site-packages/pip/_internal/utils/misc.py\", line 350, in renames\n",
      "    shutil.move(old, new)\n",
      "  File \"/usr/lib64/python3.9/shutil.py\", line 843, in move\n",
      "    rmtree(src)\n",
      "  File \"/usr/lib64/python3.9/shutil.py\", line 734, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/usr/lib64/python3.9/shutil.py\", line 690, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/usr/lib64/python3.9/shutil.py\", line 688, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "PermissionError: [Errno 13] Permission denied: 'top_level.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0mhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch==2.1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (2.1.0)\n",
      "Requirement already satisfied: transformers==4.16.2 in /home/ec2-user/.local/lib/python3.9/site-packages (4.16.2)\n",
      "Requirement already satisfied: datasets==2.9.0 in /home/ec2-user/.local/lib/python3.9/site-packages (2.9.0)\n",
      "Requirement already satisfied: tokenizers==0.14.1 in /home/ec2-user/.local/lib/python3.9/site-packages (0.14.1)\n",
      "Collecting torchvision==0.16.0\n",
      "  Downloading torchvision-0.16.0-cp39-cp39-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: sentence-transformers==2.2.2 in /home/ec2-user/.local/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch==2.1.0) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.16.2) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.16.2) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.16.2) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.16.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.16.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.16.2) (2.32.3)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.16.2) (0.1.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers==4.16.2) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==2.9.0) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.7 in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==2.9.0) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==2.9.0) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==2.9.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==2.9.0) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==2.9.0) (3.9.3)\n",
      "Requirement already satisfied: responses<0.19 in /home/ec2-user/.local/lib/python3.9/site-packages (from datasets==2.9.0) (0.18.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from torchvision==0.16.0) (10.2.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/.local/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (1.3.2)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/.local/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (1.11.0)\n",
      "Requirement already satisfied: nltk in /home/ec2-user/.local/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (3.9.1)\n",
      "Requirement already satisfied: sentencepiece in /home/ec2-user/.local/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (0.1.99)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0) (12.4.127)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.9.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.9.0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.9.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.9.0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.9.0) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.9.0) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.16.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.16.2) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.9/site-packages (from requests->transformers==4.16.2) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->transformers==4.16.2) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib64/python3.9/site-packages (from jinja2->torch==2.1.0) (3.0.2)\n",
      "Requirement already satisfied: click in /home/ec2-user/.local/lib/python3.9/site-packages (from nltk->sentence-transformers==2.2.2) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/.local/lib/python3.9/site-packages (from nltk->sentence-transformers==2.2.2) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas->datasets==2.9.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas->datasets==2.9.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas->datasets==2.9.0) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from sympy->torch==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.9.0) (1.16.0)\n",
      "Downloading torchvision-0.16.0-cp39-cp39-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchvision\n",
      "Successfully installed torchvision-0.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y diffusers facenet-pytorch gradio gradio-client torchaudio torchvision xformers aiofiles markupsafe urllib3 huggingface-hub sentence-transformers\n",
    "!pip install torch==2.1.0 transformers==4.16.2 datasets==2.9.0 tokenizers==0.14.1 torchvision==0.16.0 sentence-transformers==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee087b26c6c4226bac9d7b6947ff73e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/883 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818153608c174791ae93593ae4ab7693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d73f7bdfd5a491d9f981b4fecac03a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/333 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a637508f989416880901a9e6bb39516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891e1d8e04fe4a9489927966c12b53e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/695k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31eceed791d64df2a2311d21bf755a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-1.3230,  5.9586, -1.2204, -2.0150, -1.9393, -1.0871]],\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"TieIncred/distilbert-base-uncased-finetuned-emotional\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "text = \"I feel great about dependency conflict experiments!\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "print(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
