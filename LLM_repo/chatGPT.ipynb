{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://9759cf02b63b689d5d.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9759cf02b63b689d5d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import subprocess\n",
    "import tempfile\n",
    "import shutil\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load API key and instantiate OpenAI client\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OpenAI API key not found. Ensure it is set in the .env file.\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "##############################\n",
    "# Existing Functions (File-based)\n",
    "##############################\n",
    "\n",
    "def process_file(file):\n",
    "    \"\"\"Extract text from the uploaded file (ZIP or plain text).\"\"\"\n",
    "    if not file:\n",
    "        return \"No file uploaded.\"\n",
    "    filename = file.name\n",
    "    ext = os.path.splitext(filename)[1].lower()\n",
    "\n",
    "    if ext == \".zip\":\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            file_list = zip_ref.namelist()\n",
    "            contents = []\n",
    "            for f in file_list:\n",
    "                if \"readme\" in f.lower() or os.path.splitext(f)[1].lower() in ['.txt', '.csv', '.log']:\n",
    "                    with zip_ref.open(f) as f_in:\n",
    "                        try:\n",
    "                            text = f_in.read().decode(\"utf-8\")\n",
    "                        except UnicodeDecodeError:\n",
    "                            text = f_in.read().decode(\"latin-1\")\n",
    "                        contents.append(text)\n",
    "            return \"\\n\".join(contents) if contents else \"No readable text found in the ZIP.\"\n",
    "    elif ext in ['.txt', '.csv', '.log']:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "    else:\n",
    "        return \"File type not supported for text extraction.\"\n",
    "\n",
    "def get_command_lines_from_readme(file):\n",
    "    \"\"\"Use GPT to extract only the command-line instructions from the README-like text.\"\"\"\n",
    "    extracted_text = process_file(file)\n",
    "    if not extracted_text or \"No file\" in extracted_text or \"not supported\" in extracted_text:\n",
    "        return extracted_text\n",
    "\n",
    "    prompt = (\n",
    "        \"You are given the contents of a README file below. \"\n",
    "        \"Please extract and print only the command-line instructions. \"\n",
    "        \"Ignore all other text. Remove triple backticks, etc.\\n\\n\"\n",
    "        f\"{extracted_text}\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",   \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages\n",
    "    )\n",
    "    extracted_commands = response.choices[0].message.content\n",
    "    # Remove any leftover markdown formatting (e.g., triple backticks)\n",
    "    cleaned_commands = extracted_commands.replace(\"```bash\", \"\").replace(\"```\", \"\").strip()\n",
    "    return cleaned_commands\n",
    "\n",
    "def run_commands_live(command_text):\n",
    "    \"\"\"\n",
    "    A generator that executes shell commands dynamically and streams output live,\n",
    "    while preserving the full log history.\n",
    "    \"\"\"\n",
    "    commands = command_text.strip().splitlines()\n",
    "    error_detected = False\n",
    "    log_history = \"\"  # Accumulate logs\n",
    "\n",
    "    for cmd in commands:\n",
    "        if not cmd.strip():\n",
    "            continue  # Skip empty lines\n",
    "\n",
    "        log_history += f\"\\n---\\nRunning command: {cmd}\\n\"\n",
    "        yield log_history  # Yield the full log so far\n",
    "\n",
    "        try:\n",
    "            process = subprocess.Popen(\n",
    "                cmd,\n",
    "                shell=True,\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.PIPE,\n",
    "                text=True\n",
    "            )\n",
    "\n",
    "            # Stream stdout line-by-line\n",
    "            for line in iter(process.stdout.readline, ''):\n",
    "                log_history += line\n",
    "                yield log_history\n",
    "\n",
    "            # Check stderr for errors\n",
    "            stderr_output = process.stderr.read()\n",
    "            if stderr_output:\n",
    "                log_history += stderr_output\n",
    "                error_detected = True\n",
    "                log_history += \"\\n❌ Error detected. Stopping execution.\\n\"\n",
    "                yield log_history\n",
    "                break\n",
    "\n",
    "            exit_code = process.wait()\n",
    "            if exit_code != 0:\n",
    "                error_detected = True\n",
    "                log_history += f\"\\n❌ Error: Command failed with exit code {exit_code}. Stopping.\\n\"\n",
    "                yield log_history\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            error_detected = True\n",
    "            log_history += f\"\\n❌ Exception: {str(e)}\\n\"\n",
    "            yield log_history\n",
    "            break\n",
    "\n",
    "    if not error_detected:\n",
    "        log_history += \"\\n✅ Successfully executed all command lines without any errors.\\n\"\n",
    "        yield log_history\n",
    "\n",
    "def run_commands_with_extraction(file):\n",
    "    \"\"\"\n",
    "    1. Extract commands from the README via GPT\n",
    "    2. Yield live output as commands run\n",
    "    \"\"\"\n",
    "    commands = get_command_lines_from_readme(file)\n",
    "    if (not commands or \"No file uploaded\" in commands or \n",
    "        \"not supported\" in commands or \"No readable text\" in commands):\n",
    "        yield commands\n",
    "        return\n",
    "\n",
    "    yield from run_commands_live(commands)\n",
    "\n",
    "##############################\n",
    "# New Functions for GitHub URL-based Execution\n",
    "##############################\n",
    "\n",
    "def clone_repo(github_url):\n",
    "    \"\"\"\n",
    "    Clones the GitHub repository into a temporary directory.\n",
    "    Returns the path to the cloned repository.\n",
    "    \"\"\"\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    cmd = f\"git clone {github_url} {temp_dir}\"\n",
    "    result = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    if result.returncode != 0:\n",
    "        shutil.rmtree(temp_dir)\n",
    "        raise Exception(f\"Failed to clone repository: {result.stderr}\")\n",
    "    return temp_dir\n",
    "\n",
    "def get_command_lines_from_text(text):\n",
    "    \"\"\"\n",
    "    Uses GPT to extract command-line instructions from a given text.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"No text provided.\"\n",
    "    prompt = (\n",
    "        \"You are given the contents of a README file below. \"\n",
    "        \"Please extract and print only the command-line instructions. \"\n",
    "        \"Ignore all other text. Remove triple backticks, etc.\\n\\n\"\n",
    "        f\"{text}\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages\n",
    "    )\n",
    "    extracted_commands = response.choices[0].message.content\n",
    "    cleaned_commands = extracted_commands.replace(\"```bash\", \"\").replace(\"```\", \"\").strip()\n",
    "    return cleaned_commands\n",
    "\n",
    "def run_from_github(github_url):\n",
    "    \"\"\"\n",
    "    Clones a GitHub repository, reads the README file, extracts command-line instructions,\n",
    "    executes them live, and returns the full log.\n",
    "    \"\"\"\n",
    "    log_history = \"\"  # Initialize log accumulator\n",
    "\n",
    "    # Step 1: Clone the repository\n",
    "    try:\n",
    "        log_history += f\"Cloning repository: {github_url}\\n\"\n",
    "        yield log_history  # Update UI\n",
    "        repo_dir = clone_repo(github_url)\n",
    "        log_history += f\"Repository cloned to {repo_dir}\\n\"\n",
    "        yield log_history\n",
    "    except Exception as e:\n",
    "        log_history += f\"❌ Error cloning repository: {str(e)}\\n\"\n",
    "        yield log_history\n",
    "        return\n",
    "\n",
    "    # Step 2: Locate the README file\n",
    "    readme_path = None\n",
    "    for candidate in [\"README.md\", \"readme.md\", \"Readme.md\"]:\n",
    "        path = os.path.join(repo_dir, candidate)\n",
    "        if os.path.exists(path):\n",
    "            readme_path = path\n",
    "            break\n",
    "    if not readme_path:\n",
    "        log_history += \"❌ No README file found in the repository.\\n\"\n",
    "        yield log_history\n",
    "        shutil.rmtree(repo_dir)\n",
    "        return\n",
    "\n",
    "    log_history += f\"Found README: {readme_path}\\n\"\n",
    "    yield log_history\n",
    "\n",
    "    # Step 3: Read the README content\n",
    "    try:\n",
    "        with open(readme_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            readme_content = f.read()\n",
    "    except Exception as e:\n",
    "        log_history += f\"❌ Error reading README: {str(e)}\\n\"\n",
    "        yield log_history\n",
    "        shutil.rmtree(repo_dir)\n",
    "        return\n",
    "\n",
    "    # Step 4: Extract command-line instructions using GPT\n",
    "    log_history += \"Extracting command lines from README...\\n\"\n",
    "    yield log_history\n",
    "    commands = get_command_lines_from_text(readme_content)\n",
    "    log_history += f\"Extracted commands:\\n{commands}\\n\"\n",
    "    yield log_history\n",
    "\n",
    "    # Step 5: Execute the commands live and stream output\n",
    "    log_history += \"Executing extracted commands...\\n\"\n",
    "    yield log_history\n",
    "    for output in run_commands_live(commands):\n",
    "        log_history += output  # Append output dynamically\n",
    "        yield log_history  # Yield the full updated log\n",
    "\n",
    "    # Cleanup the cloned repository\n",
    "    shutil.rmtree(repo_dir)\n",
    "    log_history += \"Cleaned up cloned repository.\\n\"\n",
    "    yield log_history  # Final log update\n",
    "\n",
    "\n",
    "##############################\n",
    "# Gradio Interfaces\n",
    "##############################\n",
    "\n",
    "# Existing file-based interface (for uploading README or ZIP)\n",
    "file_demo = gr.Interface(\n",
    "    fn=run_commands_with_extraction,\n",
    "    inputs=gr.File(label=\"Upload README or ZIP\"),\n",
    "    outputs=gr.Textbox(label=\"Live Execution Log\", lines=15),\n",
    "    description=\"Upload a README or ZIP. We'll extract command lines using GPT, then run them line-by-line.\"\n",
    ")\n",
    "\n",
    "# New GitHub URL-based interface\n",
    "github_demo = gr.Interface(\n",
    "    fn=run_from_github,\n",
    "    inputs=gr.Textbox(label=\"GitHub Repository URL\", placeholder=\"https://github.com/username/repo.git\"),\n",
    "    outputs=gr.Textbox(label=\"Live Execution Log\", lines=15),\n",
    "    description=\"Enter a GitHub URL. The bot will clone the repo, extract command lines from the README, execute them, and return the status.\"\n",
    ")\n",
    "\n",
    "# Combine both interfaces in tabs for convenience\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Advanced Command Executor Bot\")\n",
    "    gr.Markdown(\"Choose an input method:\")\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"File Upload\"):\n",
    "            file_demo.render()\n",
    "        with gr.TabItem(\"GitHub URL\"):\n",
    "            github_demo.render()\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
