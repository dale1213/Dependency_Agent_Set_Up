{
    "https://github.com/cudbg/Kitana-e2e": [
        "\n\n# Kitana e2e \n\n\n## Data Augmentation for Kitana\nThis repository contains the scalable e2e implementation for data augmentation for Kitana. The code is written in Python and contains sample data, sample execution code, and the data augmentation code.\n\nPlease follow the instructions below to run the code.\n\n### Instructions\n1. Clone the repository\n2. Make sure you are in the correct directory:\n```bash\ncd kitana-e2e\n```\n3. Run the following command to install the required libraries:\n```bash\n# If you are using python venv.\npython3 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n```\n\n```bash\n# If you are using conda, there is a environment.yml file in the repository.\nconda env create -f environment.yml\n```\n3. Run the following command to execute the code:\n```bash\npython sample_execution.py\n``` \n## Project Structure\n- **`api/`** - Contains the interfaces for external modules to interact with the core functionality of the search engine.\n- **`config/`** - Configuration settings for the project, including default paths, device settings, etc.\n- **`data_provider/`** - Core modules for data management, handling buyer and seller data.\n- **`market/`** - It loads the buyer and seller data.\n- **`models/`** - Defines all data models used throughout the project, including loaders and specific models for buyers and sellers.\n- **`preprocessing/`** - Data preprocessing utilities, ensuring data is clean and formatted correctly before entering the workflow.\n- **`resources/`** - Manages and optimizes computing resources, ensuring efficient use of available hardware.\n- **`search/`** - Core search engine functionality, implementing the algorithms that enhance buyer dataset with seller features.\n- **`sketches/`** - Contains the sketches for the data augmentation process. It is indexed by the `join_keys`.\n- **`statistics/`** - Statistical tools and functions. It contains a linear regression model to determine the augmentation effect.\n- **`utils/`** - General utilities used across the project for a variety of support tasks.\n- **`main.py`** - The entry point of the project, initializing and starting the search engine.\n",
        "﻿bidict==0.23.1\nblinker==1.8.2\nboto3==1.34.14\nbotocore==1.34.14\ncertifi==2023.11.17\ncharset-normalizer==3.3.2\nclick==8.1.7\ncolorama==0.4.6\ncontourpy==1.3.0\ncycler==0.12.1\nexceptiongroup==1.2.2\nfilelock==3.16.1\nFlask==3.0.0\nFlask-SocketIO==5.3.6\nfonttools==4.54.1\nfsspec==2023.12.2\nh11==0.14.0\nidna==3.6\nimportlib-metadata==7.0.1\nimportlib_resources==6.4.5\niniconfig==2.0.0\nitsdangerous==2.2.0\nJinja2==3.1.2\njmespath==1.0.1\njoblib==1.3.2\nkiwisolver==1.4.7\nMarkupSafe==3.0.2\nmatplotlib==3.9.2\nmpmath==1.3.0\nnetworkx==3.2.1\nnumpy==1.26.3\npackaging==24.1\npandas==2.1.4\npillow==11.0.0\npluggy==1.5.0\npsutil==5.9.7\npyparsing==3.2.0\npytest==8.3.3\npytest-mock==3.14.0\npython-dateutil==2.9.0.post0\npython-engineio==4.10.1\npython-socketio==5.11.4\npytz==2024.2\nPyYAML==6.0.2\nrequests==2.31.0\ns3transfer==0.10.3\nscikit-learn==1.3.2\nscipy==1.11.4\nsimple-websocket==1.1.0\nsix==1.16.0\nsympy==1.13.1\nthreadpoolctl==3.5.0\ntomli==2.0.2\ntorch==2.5.0\ntorchaudio==2.5.0\ntorchvision==0.20.0\ntqdm==4.66.5\ntyping_extensions==4.12.2\ntzdata==2024.2\nurllib3==1.26.18\nWerkzeug==3.0.1\nwsproto==1.2.0\nxgboost==2.0.3\nzipp==3.20.2",
        64,
        ["python sample_execution.py"]
    ],
    "https://github.com/dale1213/2020-Coding-Challenge": [
        "# 2020-Columbia-Build-Lab-Coding-Exercise\n\nThank you for your interest in joining Columbia Build Lab!\n\nThis is a simple coding exercise designed to see your proficiency in web programming. \nAlthough it is written in Python and JS using flask framework, you don't need prior experience with them to complete the exercise - you are welcome and encouraged to use any online resources. \nThis exercise should take no longer than 1 hour, though you are welcome to take as much time as you need.\n\nThis exercise is designed to see how well you can read others' code, and extend it. As such, most of the code is already written - you only need to add a couple lines of code at the right place. \n\nIf you don't have flask on your computer, please install it with $pip install Flask. You can fork this repository and clone it to your desktop. You can run the code with $python3 server.py. Once you run it, you can type in http://127.0.0.1:5000/ on your browser to see the webpage rendered locally.\n\nYou'll see a short list of NHL teams, their scores, and buttons to increase their scores. Right now, clicking on a button doesn't increase the score immediately, but you need to refresh the page to see the change. The goal is to reflect this change immediately on the front-end. Once that's done, we would also like to sort the teams so that whenever there's a score change, the list would change so that the teams are listed in non-increasing order of scores from top to bottom (you don't need to sort them alphabetically when there is a tie). To do these, you would need to make changes in both server.py file and scoreboard.js file. When you're done, please send a pull request to this repository with your name and uni in the comment. Thanks and good luck!\n\n",
        "",
        0,
        ["python server.py"]
    ],
    "https://github.com/mtayseer/infoq-downloader": [
        "# InfoQ downloader\n\n[InfoQ](http://www.infoq.com/) is a great resource for many useful sessions. The way they view presentations sync'ed with slides is cool. Unfortunately, I have a slow internet connection which makes my viewing experience sucks. To solve this, I made this scripts which downloads their page, video & slides.\n\n## Installation\nOn Windows, just download [this file](dist/infoq_downloader.exe?raw=true)\n\nOn Linux, run the following\n\n```sh\ngit clone https://github.com/mtayseer/infoq-downloader.git\ncd infoq-downloader\npip install -r requirements.txt\n```\n\n## Usage\n`python infoq_downloader.py http://www.infoq.com/presentations/github-evolution`\n\nOn Windows\n`infoq_downloader.exe http://www.infoq.com/presentations/github-evolution`\n\n## Features\n1. Console app\n2. Supports download resuming of slides & videos\n3. The generated HTML is clean\n\n## License\nMIT. See [LICENSE](LICENSE)",
        "requests\nlxml\ncssselect",
        3,
        ["python infoq_downloader.py http://www.infoq.com/presentations/github-evolution"],
        "IndexError: list index out of range",
        "Error: the wesite structure has changed, the code is not working anymore"

    ],
    "https://github.com/sangmin-git/LMC-Memory": [
        "## Video Prediction Recalling Long-term Motion Context via Memory Alignment Learning \n\n\n<div align=\"center\"><img width=\"98%\" src=\"https://user-images.githubusercontent.com/41602474/112792595-bc1a3a00-909e-11eb-9d7c-9890fdb2b254.PNG\" /></div>\n\n\n> \nThis repository contains the official PyTorch implementation of the following paper:\n> **Video Prediction Recalling Long-term Motion Context via Memory Alignment Learning (CVPR 2021 Oral)**<br>\n> Sangmin Lee, Hak Gu Kim, Dae Hwi Choi, Hyung-Il Kim, and Yong Man Ro<br>\n> Paper: https://arxiv.org/abs/2104.00924<br>\n> \n> **Abstract** *Our work addresses long-term motion context issues for predicting future frames. To predict the future precisely, it is required to capture which long-term motion context (e.g., walking or running) the input motion (e.g., leg movement) belongs to. The bottlenecks arising when dealing with the long-term motion context are: (i) how to predict the long-term motion context naturally matching input sequences with limited dynamics, (ii) how to predict the long-term motion context with high-dimensionality (e.g., complex motion). To address the issues, we propose novel motion context-aware video prediction. To solve the bottleneck (i), we introduce a long-term motion context memory (LMC-Memory) with memory alignment learning. The proposed memory alignment learning enables to store long-term motion contexts into the memory and to match them with sequences including limited dynamics. As a result, the long-term context can be recalled from the limited input sequence. In addition, to resolve the bottleneck (ii), we propose memory query decomposition to store local motion context (i.e., low-dimensional dynamics) and recall the suitable local context for each local part of the input individually. It enables to boost the alignment effects of the memory. Experimental results show that the proposed method outperforms other sophisticated RNN-based methods, especially in long-term condition. Further, we validate the effectiveness of the proposed network designs by conducting ablation studies and memory feature analysis. The source code of this work is available.*\n\n## Preparation\n\n### Requirements\n- python 3\n- pytorch 1.6+\n- opencv-python\n- scikit-image\n- lpips\n- numpy\n\n### Datasets\nThis repository supports Moving-MNIST and KTH-Action datasets. \n- [Moving-MNIST](https://github.com/jthsieh/DDPAE-video-prediction/blob/master/data/moving_mnist.py)\n- [KTH-Action](https://www.csc.kth.se/cvap/actions/)\n\nAfter obtaining the datasets, preprocess the data as image files (refer to below). \n```shell\n# Dataset preparation example:\nmovingmnist\n├── train\n│   ├── video_00000\n│   │   ├── frame_00000.jpg\n...\n│   │   ├── frame_xxxxx.jpg\n...\n│   ├── video_xxxxx\n```\n\n## Training the Model\n`train.py` saves the weights in `--checkpoint_save_dir` and shows the training logs.\n\nTo train the model, run following command:\n```shell\n# Training example for Moving-MNIST\npython train.py \\\n--dataset 'movingmnist' \\\n--train_data_dir 'enter_the_path' --valid_data_dir 'enter_the_path' \\\n--checkpoint_save_dir './checkpoints' \\\n--img_size 64 --img_channel 1 --memory_size 100 \\\n--short_len 10 --long_len 30 --out_len 30 \\\n--batch_size 128 --lr 0.0002 --iterations 300000\n```\n```shell\n# Training example for KTH-Action\npython train.py \\\n--dataset 'kth' \\\n--train_data_dir 'enter_the_path' --valid_data_dir 'enter_the_path' \\\n--checkpoint_save_dir './checkpoints' \\\n--img_size 128 --img_channel 1 --memory_size 100 \\\n--short_len 10 --long_len 40 --out_len 40 \\\n--batch_size 32 --lr 0.0002 --iterations 300000\n```\nDescriptions of training parameters are as follows:\n- `--dataset`: training dataset (movingmnist or kth)\n- `--train_data_dir`: directory of training set  `--valid_data_dir`: directory of validation set\n- `--checkpoint_save_dir`: directory for saving checkpoints\n- `--img_size`: height and width of frame  `--img_channel`: channel of frame  `--memory_size`: memory slot size\n- `--short_len`: number of short frames  `--long_len`: number of long frames  `--out_len`: number of output frames\n- `--batch_size`: mini-batch size  `--lr`: learning rate  `--iterations`: number of total iterations\n- Refer to `train.py` for the other training parameters\n\n## Testing the Model\n`test.py` saves the predicted frames in `--test_result_dir` or evalute the performances.\n\nTo test the model, run following command:\n```shell\n# Testing example for Moving-MNIST\npython test.py \\\n--dataset 'movingmnist' --make_frame True \\\n--test_data_dir 'enter_the_path' --test_result_dir 'enter_the_path' \\\n--checkpoint_load_file 'enter_the_path' \\\n--img_size 64 --img_channel 1 --memory_size 100 \\\n--short_len 10 --out_len 30 \\\n--batch_size 8\n```\n```shell\n# Testing example for KTH-Action\npython test.py \\\n--dataset 'kth' --make_frame True \\\n--test_data_dir 'enter_the_path' --test_result_dir 'enter_the_path' \\\n--checkpoint_load_file 'enter_the_path' \\\n--img_size 128 --img_channel 1 --memory_size 100 \\\n--short_len 10 --out_len 40 \\\n--batch_size 8\n```\nDescriptions of testing parameters are as follows:\n- `--dataset`: test dataset (movingmnist or kth)  `--make_frame`: whether to generate predicted frames\n- `--test_data_dir`: directory of test set  `--test_result_dir`: directory for saving predicted frames\n- `--checkpoint_load_file`: file path for loading checkpoint\n- `--img_size`: height and width of frame  `--img_channel`: channel of frame  `--memory_size`: memory slot size\n- `--short_len`: number of short frames  `--out_len`: number of output frames\n- `--batch_size`: mini-batch size\n- Refer to `test.py` for the other testing parameters\n\n## Pretrained Models\nYou can download the pretrained models.\n- [Pretrained model for Moving-MNIST](https://www.dropbox.com/s/c2yl2f7znzmj8mf/trained_file_movingmnist.pt?dl=0)\n- [Pretrained model for KTH-Action](https://www.dropbox.com/s/nt015y70moqgy76/trained_file_kth.pt?dl=0)\n\n## Citation\nIf you find this work useful in your research, please cite the paper:\n```\n@inproceedings{lee2021video,\n  title={Video Prediction Recalling Long-term Motion Context via Memory Alignment Learning},\n  author={Lee, Sangmin and Kim, Hak Gu and Choi, Dae Hwi and Kim, Hyung-Il and Ro, Yong Man},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n  year={2021}\n}\n```\n",
        "torch==1.6.0\nopencv-python\nscikit-image\nlpips\nnumpy\n",
        5,
        ["python train.py --dataset 'movingmnist' --train_data_dir 'path' --valid_data_dir 'path'", "python test.py --dataset 'movingmnist' --make_frame True --test_data_dir 'path' --test_result_dir 'path' --checkpoint_load_file 'path' --img_size 64 --img_channel 1 --memory_size 100 --short_len 10 --out_len 30 --batch_size 8"],
        "No matching distribution found for torch==1.6.0",
        "Error: the torch version is not available for download anymore"
    ],
    "https://github.com/SudoSuu/SnapchatUsernameChecker": [
        "# Simple Snapchat Username Checker\n## Requirements\n- Python 3.6\n- requests\n- colorama\n- pyfiglet\n\n## OS\n- Linux\n- Windwos\n- Mac\n\n## Installing\n\n**Git:**\n```bash\ngit clone https://github.com/SudoSuu/SnapchatUsernameChecker.git\ncd SnapchatUsernameChecker\npip3 install -r requirements.txt\npython3 snapchat.py\n```\n\n\n## Check a single username\n - run snapchat.py\n - Option 1 \n - Enter the username\n\n![1](https://raw.githubusercontent.com/SudoSuu/SnapchatUsernameChecker/su/screenshots/s.png)\n\n\n\n## Check from list\n- run snapchat.py\n- Option 2 \n- Enter the path list of the usernames\n\n\n# Ways to Create Usernames\n- Crunch\n- Cewl\n- Cupp\n- Pydictor\n- Dymerge\n\n**Example in Crunch**\n\n**Crunch Syntax**\n```\ncrunch <min> max<max> <characterset> -t <pattern> -o <output filename>\n```\n\n\n```bash\ncrunch 3 3  -o 3letters.txt\n```\n**3letters.txt**\n```\naaa\naab\naac\naad\naae\naaf\naag\naah\naai\naaj\naak\naal\naam\naan\naao\naap\naaq\naar\naas\naat\naau\naav\naaw\naax\naay\naaz\n............... \n```\n![1](https://raw.githubusercontent.com/SudoSuu/SnapchatUsernameChecker/su/screenshots/3.png)\n\n**OR**\n\n```bash\ncrunch 7 7 0123456789 -t sudosu@  -o usernames.txt\n```\n\n**usernames.txt**\n```\nsudosu0\nsudosu1\nsudosu2\nsudosu3\nsudosu4\nsudosu5\nsudosu6\n............... \n```\n![1](https://raw.githubusercontent.com/SudoSuu/SnapchatUsernameChecker/su/screenshots/sudosu.png)\n\n\n\n\n\n\n\n",
        "requests\ncolorama\npyfiglet\n",
        3,
        ["python3 snapchat.py"],
        " ____            _      ____              \n/ ___| _   _  __| | ___/ ___| _   _ _   _ \n\\___ \\| | | |/ _` |/ _ \\___ \\| | | | | | |\n___) | |_| | (_| | (_) |__) | |_| | |_| |\n|____/ \\__,_|\\__,_|\\___/____/ \\__,_|\\__,_|\n\nSnapchat Username Checker\nBy: SudoSuu\n\n[1] Check a single username\n[2] Check from list\nSelect an option: \n[1] Check a single username\n[2] Check from list\nSelect an option: ",
        "Success"
    ],
    "https://github.com/UsamaKashif/CambridgePastPapersDownloader": [
        "# CambridgePastPapersDownloader\nDownload O/A Levels (GCSE) and IGCSE Papers\n\nYou can clone or download the code or you can download the executable from <b><a href=\"https://drive.google.com/file/d/1UCA0ZxL76QGgPL5CKveVNdJMUXhFfkWB/view?usp=sharing\">HERE</a></b>\n\nThe image below shows the demo of the application\n\n![img1](https://user-images.githubusercontent.com/49620321/67022963-76241d00-f11b-11e9-98f5-895eeaa0cfb8.jpg)\n\n\n<b style=\"font-size=30\">How this app works?</b>\n  1) select any 1 course from the 3 available\n  2) Select what you want to download (Question paper / marking scheme)\n  3) Choose between single paper or multiple paper options \n  4) Provide the paper number \n  5) Using your information provided the app downloads the paper(s)\n  6) Directory named <b>\"Downloads\"</b> is created if it does not exists\n  7) inside the <b>\"Downloads\"</b> folder another directory is created with same name of the paper      downloaded\n  8) inside that folder your papers are downloaded\n  9) finally you are asked whether you want to download more or stop \n  \n<hr>\n  \n<b>If you are using the code make sure to download the libraries used. Check the requirements.txt file for the libraries used.</b>\n<br>\nTo run the code type the following command in the CLI\n<br>\n<b>python scraper.py</b>\n",
        "requests==2.22.0\nbeautifulsoup4==4.8.1\n",
        2,
        ["python scraper.py"],
        "Choose from the following options:\nCambridge AS & A Level \nCambridge Olevel\nCambridge IGCSE",
        "Success"
    ],
    "https://github.com/berkgoksel/sysref": [
        "# sysref\nLinux Syscall Reference Table for x86, x64, arm32 and arm64, searchable via CLI.\n\n\n## Usage\n```\n$ pip3 install -r requirements.txt\n$ python3 sysref.py -a <architecture> <keyword>\n```\n\n### Example Usage\n```\n$ python3 sysref.py -a x86 -s sys_open\n$ python3 sysref.py -a x86 dup\n```\n\n## TODO\n- Add argument for shorter output (no reference, no syscall number)\n- Provide HTML output\n- Support for RISC-V\n\n## Acknowledgements\nSyscall table for x86:\n- [Linux Syscall Reference](https://syscalls.kernelgrok.com)\n\nSyscall table for x64:\n- Filippo Valsorda's [Searchable Linux Syscall Table for x86 and x86_64](https://filippo.io/linux-syscall-table/)\n\nSyscall tables for arm32 and arm64:\n- https://chromium.googlesource.com/chromiumos/docs/+/master/constants/syscalls.md\n",
        "tabulate==0.8.6\n",
        1,
        ["python3 sysref.py -a x86 -s sys_open"],
        "╒═══════╤═══════════╤═══════╤═════════════════════════════╤═══════════╤══════════╤═══════╤═══════╤═══════════════╕\n│   num │ syscall   │ eax   │ ebx                         │ ecx       │ edx      │ esi   │ edi   │ REF           │\n╞═══════╪═══════════╪═══════╪═════════════════════════════╪═══════════╪══════════╪═══════╪═══════╪═══════════════╡\n│     5 │ sys_open  │ 0x05  │ const char __user *filename │ int flags │ int mode │ -     │ -     │ fs/open.c:900 │\n╘═══════╧═══════════╧═══════╧═════════════════════════════╧═══════════╧══════════╧═══════╧═══════╧═══════════════╛",
        "Success"
    ],
    "https://github.com/slub/statsdelta": [
        "# statsdelta - statistics delta\n\nstatsdelta is a commandline command (Python3 program) that compares two (CSV) statistics with each other and generates delta values from the (old and the new) values.\n\n## Usage\n\n```\nstatsdelta\n\nrequired arguments:\n  -from FROM_FILE                      The file to use as the left or from source for the delta calculation (default: None)\n  -to TO_FILE                          The file to use as the right or to source for the delta calculation (default: None)\n  -key-field KEY_FIELD                 The key field name (column name) (default: None)\n\noptional arguments:\n  -h, --help                           show this help message and exit\n  -delimiter DELIMITER                 The field delimiter used within the file; use TAB for tab-delimited (default: ,)\n  -output-fields OUTPUT_FIELDS         The names of the fields (column names) to include in the delta output (if this argument is not specified, then the header from the \"from\" CSV file is taken (i.e. all columns from the \"from\" CSV file); it's always mandatory that these columns only contain numeric values (otherwise an error will be thrown at processing time)) (default: None)\n```\n\n* example:\n    ```\n    statsdelta -from [PATH THE FROM CSV FILE] -to [PATH TO THE TO CSV FILE] -key-field [KEY FIELD NAME] > [PATH TO THE OUTPUT CSV FILE]\n    ```\n\n### Note\n\nPlease make sure that the choosen output fields (columns) only contain numeric values (otherwise an error will be thrown at processing time). This is especially important when the argument '-output-fields' is not specified, because then the header from the \"from\" CSV file is taken (i.e. all columns from the \"from\" CSV file).\n\n### Current Limitations\n\nCurrently, column indices/numbers are not supported (see [issue #1](https://github.com/slub/statsdelta/issues/1)), i.e., only column names. So header in the CSV files are mandatory.\n\n## Run\n\n* clone this git repo or just download the [statsdelta.py](statsdelta/statsdelta.py) file\n* run ./statsdelta.py\n* for a hackish way to use statsdelta system-wide, copy to /usr/local/bin\n\n### Install system-wide via pip\n\n```\nsudo -H pip3 install --upgrade [ABSOLUTE PATH TO YOUR LOCAL GIT REPOSITORY OF STATSDELTA]\n```\n(which provides you ```statsdelta``` as a system-wide commandline command)\n\n## Description\n\n### Diff Status\n\n|Diff Status|Description|\n|-----------|-----------|\n|changed|some values (/statistics; included in this comparison) have been changed for this field (key)|\n|not changed|no values (/statistics; included in this comparison) have been changed for this field (key)|\n|added|this field (key) has been added to the 'to' statistic|\n|deleted|this field (key) has been removed from the 'to' statistic|\n",
        "argparse>=1.4.0",
        1,
        ["python statsdelta/statsdelta.py"],
        "usage: statsdelta [-h] -from FROM_FILE -to TO_FILE -key-field KEY_FIELD [-delimiter DELIMITER] [-output-fields OUTPUT_FIELDS]\nstatsdelta: error: the following arguments are required: -from, -to, -key-field",
        "Error: the following arguments are required: -from, -to, -key-field, but no csv provided for test"
    ],  
    "https://github.com/danielegrattarola/SRC": [
        "# Select, Reduce, Connect\n\n![](images/src.png)\n\nThis repository contains the code used for the experiments of:\n\n**\"Understanding Pooling in Graph Neural Networks\"**   \nD. Grattarola, D. Zambon, F. M. Bianchi, C. Alippi  \nhttps://arxiv.org/abs/2110.05292\n\n\n# Setup\n\nThe dependencies of the project are listed in requirements.txt. You can install them with: \n\n```bash\npip install -r requirements.txt\n```\n\n# Running experiments\n\nThe code to run our experiments is in the following folders: \n\n- `autoencoder/`\n- `spectral_similarity/`\n- `graph_classification/`\n\nEach folder has a script called `run_all.sh` that will reproduce the results reported in the paper. \n\nTo generate the plots and tables from the paper, you can use the `plots.py`, `plots_datasets.py`, or `tables.py` scripts in each folder.\n\nTo run experiments for an individual pooling operator, you can use the `run_[OPERATOR NAME].py` scripts in each folder. \n\nThe pooling operators that we used for the experiments are in `layers/` (trainable) and `modules/` (non-trainable).\nThe GNN architectures used in the experiments are in `models/`. \n\n# The SRCPool class\n\nThe core of this repository is the `SRCPool` class that implements a general \ninterface to create SRC pooling layers with the Keras API.\n\nOur implementation of MinCutPool, DiffPool, LaPool, Top-K, and SAGPool using the\n`SRCPool` class can be found in `src/layers`.\n\nSRC layers have the following structure \n$$\\mathcal{S} = \\mathrm{SEL}( \\mathcal{G} ) = \\\\\\{\\mathcal{S}\\_k \\\\\\}\\_{k=1:K}; \\\\;\\\\; \\mathcal{X}' = \\\\\\{\\mathrm{RED}( \\mathcal{G}, \\mathcal{S}\\_k ) \\\\\\}\\_{k=1:K}; \\\\;\\\\; \\mathcal{E}' = \\\\\\{\\mathrm{CON}( \\mathcal{G}, \\mathcal{S}\\_k, \\mathcal{S}\\_l )\\\\\\}\\_{k,l=1:K}$$\n\nwhere $\\textrm{SEL}$ is a permutation-equivariant selection function that computes the supernodes $\\mathcal{S}_k$, $\\textrm{RED}$ is a permutation-invariant function to reduce the supernodes into the new node attributes, and $\\textrm{CON}$\nis a permutation-invariant connection function that computes the edges among the new nodes.\n\nBy extending this class, it is possible to create any pooling layer in the\nSRC framework.\n\n**Input**\n\n- `X`: Tensor of shape `([batch], N, F)` representing node features;\n- `A`: Tensor or SparseTensor of shape `([batch], N, N)` representing the\nadjacency matrix;\n- `I`: (optional) Tensor of integers with shape `(N, )` representing the\nbatch index;\n\n**Output**\n\n- `X_pool`: Tensor of shape `([batch], K, F)`, representing the node\nfeatures of the output. `K` is the number of output nodes and depends on the\nspecific pooling strategy;\n- `A_pool`: Tensor or SparseTensor of shape `([batch], K, K)` representing\nthe adjacency matrix of the output;\n- `I_pool`: (only if `I` was given as input) Tensor of integers with shape\n`(K, )` representing the batch index of the output;\n- `S_pool`: (if `return_sel=True`) Tensor or SparseTensor representing the\nsupernode assignments;\n\n**API**\n\n- `pool(X, A, I, **kwargs)`: pools the graph and returns the reduced node\nfeatures and adjacency matrix. If the batch index `I` is not `None`, a\nreduced version of `I` will be returned as well.\nAny given `kwargs` will be passed as keyword arguments to `select()`,\n`reduce()` and `connect()` if any matching key is found.\nThe mandatory arguments of `pool()` (`X`, `A`, and `I`) **must** be computed in \n`call()` by calling `self.get_inputs(inputs)`.\n- `select(X, A, I, **kwargs)`: computes supernode assignments mapping the\nnodes of the input graph to the nodes of the output.\n- `reduce(X, S, **kwargs)`: reduces the supernodes to form the nodes of the\npooled graph.\n- `connect(A, S, **kwargs)`: connects the reduced supernodes.\n- `reduce_index(I, S, **kwargs)`: helper function to reduce the batch index\n(only called if `I` is given as input).\n\nWhen overriding any function of the API, it is possible to access the\ntrue number of nodes of the input (`N`) as a Tensor in the instance variable\n`self.N` (this is populated by `self.get_inputs()` at the beginning of\n`call()`).\n\n**Arguments**:\n\n- `return_sel`: if `True`, the Tensor used to represent supernode assignments\nwill be returned with `X_pool`, `A_pool`, and `I_pool`;\n",
        "# These versions are the ones that were used to obtain the results in the paper\n# More recent versions of the libraries could also work\nspektral==1.1\nnumpy==1.19.5\nnetworkx==2.5\npandas==1.2.3\nPyGSP==0.5.1\nscikit-learn==0.23.1\nscipy==1.4.1\ntensorflow==2.4.0\n",
        8,
        ["./autoencoder/run_all.sh", "./spectral_similarity/run_all.sh", "./graph_classification/run_all.sh"],
        "No module named 'src'",
        "Error: the root directory not well defined. A dead loop is there."
    ],
    "https://github.com/Xennis/epidoc-parser": [
        "# EpiDoc Parser\n\n[![Python](https://github.com/Xennis/epidoc-parser/actions/workflows/python.yml/badge.svg?branch=main&event=push)](https://github.com/Xennis/epidoc-parser/actions/workflows/python.yml?query=event%3Apush+branch%3Amain)\n\nPython parser for EpiDoc (epigraphic documents in TEI XML).\n\nFor example [idp.data-sheet](https://github.com/Xennis/idp.data-sheet) uses the parser to generate a single CSV sheet of the [Papyri.info Integrating Digital Papyrology data](https://github.com/papyri/idp.data).\n\n## Usage\n\n### Installation \n\nInstall the package\n```shell\npip install git+https://github.com/Xennis/epidoc-parser\n```\n\n### Load a document\n\nLoad a document from a file\n```python\nimport epidoc\n\nwith open(\"my-epidoc.xml\") as f:\n    doc = epidoc.load(f)\n```\n\nLoad a document from a string\n```python\nimport epidoc\n\nmy_epidoc = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<?xml-model href=\"http://www.stoa.org/epidoc/schema/8.13/tei-epidoc.rng\" type=\"application/xml\" schematypens=\"http://relaxng.org/ns/structure/1.0\"?>\n<TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"hgv74005\">\n   [...]\n</TEI>\n\"\"\"\n\ndoc = epidoc.loads(my_epidoc)\n```\n\n### Get data from a document\n\nCall the attributes, for example\n```python\n>>> doc.title\n\"Ordre de paiement\"\n>>> doc.material\n\"ostrakon\"\n>>> doc.languages\n{\"en\": \"Englisch\", \"la\": \"Latein\", \"el\": \"Griechisch\"}\n>>> [t.get(\"text\") for t in doc.terms]\n[\"Anweisung\", \"Zahlung\", \"Getreide\"]\n>>> doc.origin_place.get(\"text\")\n\"Kysis (Oasis Magna)\"\n>>> doc.origin_dates[0]\n{\"notbefore\": \"0301\", \"notafter\": \"0425\", \"precision\": \"low\", \"text\": \"IV - Anfang V\"}\n```\n\n## Documentation\n\n| Field                     | EpiDoc source element (XPath)                                                  |\n|---------------------------|--------------------------------------------------------------------------------|\n| commentary                | `//body/div[@type='commentary' and @subtype='general']`                        |\n| edition_foreign_languages | `//body/div[@type='edition']//foreign/@xml:lang`                               |\n| edition_language          | `//body/div[@type='edition']/@xml:lang`                                        |\n| idno                      | `//teiHeader/fileDesc/publicationStmt/idno`                                    |\n| authority                 | `//teiHeader/fileDesc/publicationStmt/authority`                               |\n| availability              | `//teiHeader/fileDesc/publicationStmt/availability`                            |\n| languages                 | `//teiHeader/profileDesc/langUsage/language`                                   |\n| material                  | `//teiHeader/fileDesc/sourceDesc/msDesc/physDesc/objectDesc//support/material` |\n| origin_dates              | `//teiHeader/fileDesc/sourceDesc/msDesc/history/origin/origDate`               |\n| origin_place              | `//teiHeader/fileDesc/sourceDesc/msDesc/history/origin/origPlace`              |\n| provenances               | `//teiHeader/fileDesc/sourceDesc/msDesc/history/provenance`                    |\n| reprint_from              | `//body/ref[@type='reprint-from']`                                             |\n| reprint_in                | `//body/ref[@type='reprint-in']`                                               |\n| terms                     | `//teiHeader/profileDesc/textClass//term`                                      |\n| title                     | `//teiHeader/fileDesc/titleStmt/title`                                         |\n\n## Development\n\nCreate a virtual environment, enable it and install the dependencies\n```shell\npython3 -m venv venv\n. venv/bin/activate\npip install --requirement requirements.txt\n```\n\nRun the test\n```shell\nmake unittest\n```\n\n## LICENSE\n\n### Code\n\nsee [LICENSE](LICENSE)\n\n### Test data\n\nThe test data in this project is from the project [idp.data](https://github.com/papyri/idp.data) by [Papyri.info](http://papyri.info). This data is made available under a [Creative Commons Attribution 3.0 License](http://creativecommons.org/licenses/by/3.0/), with copyright and attribution to the respective projects.\n",
        "beautifulsoup4==4.12.3\nblack==25.1.0  # Code formatter\nlxml==5.3.0\nmypy==1.14.1  # Type checker\nsetuptools==75.8.0  # Only required for publish it as a package\ntypes-beautifulsoup4==4.12.0.20241020  # Stubs for beautifulsoup4\nwheel==0.45.1  # Only required for publish it as a package\n",
        7,
        ["make unittest"],
        "python -m unittest discover\n/home/ec2-user/repo_temp/repos/epidoc-parser/epidoc/api.py:84: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n\nAssuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n\nIf you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n\n    from bs4 import XMLParsedAsHTMLWarning\n    import warnings\n\n    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n\n  soup = BeautifulSoup(s, features=\"lxml\")\n/home/ec2-user/repo_temp/repos/epidoc-parser/epidoc/body.py:36: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.\n  for elem in body.findAll(\"ref\", type=\"reprint-from\"):\n/home/ec2-user/repo_temp/repos/epidoc-parser/epidoc/body.py:45: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.\n  for elem in body.findAll(\"ref\", type=\"reprint-in\"):\n/home/ec2-user/repo_temp/repos/epidoc-parser/epidoc/header.py:12: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.\n  for elem in history.origin.findAll(\"origdate\"):  # type: ignore\n/home/ec2-user/repo_temp/repos/epidoc-parser/epidoc/header.py:30: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.\n  for elem in history.findAll(\"provenance\"):\n/home/ec2-user/repo_temp/repos/epidoc-parser/epidoc/header.py:69: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.\n  for elem in lang_usage.findAll(\"language\"):\n/home/ec2-user/repo_temp/repos/epidoc-parser/epidoc/header.py:57: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.\n  for elem in textclass.keywords.findAll(\"term\"):  # type: ignore\n/home/ec2-user/repo_temp/repos/epidoc-parser/epidoc/header.py:41: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.\n  for elem in provenance.findAll(\"placename\"):\n........\n----------------------------------------------------------------------\nRan 8 tests in 0.074s\n\nOK",
        "Success"
    ],
    "https://github.com/liyaooi/FETCH": [
        "# FETCH\n\n## Introduction\nCode for [**\"Learning a Data-Driven Policy Network for Pre-Training Automated Feature Engineering \"**](https://openreview.net/forum?id=688hNNMigVX)\n\n> Accepted in ICLR 2023 Conference\n\nThis is an automated feature engineering framework \"FETCH\", implemented in PyTorch.\nData can be accessed through URL in the paper.\n\n## How to run it\n\n`pip install -r requirements.txt`: install needed packages under the environment settings by pip.\n\n`python main_attention.py`: after specifying the dataset, cuda, and other parameters, you can run FETCH to automate feature engineering for Random Forest or other pre-defined model.\n\n`. run_table_1.sh`: run Experiment 4.2.\n\n`. run_table_3.sh`: run Experiment C.3 on large-scale dataset (> 50k rows).\n\n`. run_eval_pretrain.sh`: run Experiment 4.3 on evaluating pre-trained models.\n\n`. run_diff_models.sh`: run Experiment 4.4 and C.5 on different models.\n\n`. run_table_5.sh`: run Experiment C.6.\n\n## Environment\nThe code in this repository is designed and highly recommended to be run on `Ubuntu 20.04` or other Linux systems.\n\n> Note that running the code with multiple processes (`args.worker > 1`) on `Windows` may encounter issues with variable sharing. \n> If you are using `Windows`, consider setting up a Linux environment (e.g., using a virtual machine or WSL) to run the code.\n\n## Citation\n```\n@inproceedings{li2023learning,\n  title={Learning a Data-Driven Policy Network for Pre-Training Automated Feature Engineering},\n  author={Li, Liyao and Wang, Haobo and Zha, Liangyu and Huang, Qingyi and Wu, Sai and Chen, Gang and Zhao, Junbo},\n  booktitle={The Eleventh International Conference on Learning Representations},\n  year={2023}\n}\n```\n\n## Reference Code\n\n- NFS: https://github.com/TjuJianyu/NFS\n- DIFER: https://github.com/PasaLab/DIFER",
        "catboost==1.0.5\nlightgbm==3.3.2\nnumpy==1.20.2\npandas==1.3.3\nscikit_learn==1.2.1\nscipy==1.7.1\ntorch==1.13.0\nxgboost==1.5.2\n",
        8,
        ["python main_attention.py"],
        "2025-03-07 07:01:49,990 ppo.py:189 update_c INFO | total_loss_c:-0.18508809499257484,actor_loss:-0.17749725618757858,entory_loss:-0.007590839639306068\n2025-03-07 07:01:50,495 ppo.py:189 update_c INFO | total_loss_c:-0.1943661274245075,actor_loss:-0.18678917657935412,entory_loss:-0.007576949894428253\n2025-03-07 07:01:50,943 ppo.py:189 update_c INFO | total_loss_c:-0.2037595277472658,actor_loss:-0.19619816338090332,entory_loss:-0.0075613646768033504",
        "Success"
    ],
    "https://github.com/friendlysapphire/simple_url_shortener": [
        "# Simple URL Shortener\n\nSimple URL Shortener is an extremely basic URL shortening service written in Python using [Bottle](https://bottlepy.org),\nthe [bottle-sqlite plugin](https://pypi.org/project/bottle-sqlite/), and [Hashids](https://hashids.org/python/).\n\n## Routes\n\nIt supports the following routes:\n\n    * / and /new/\n        Loads the page to create a new short URL.\n\n    * /stats/\n        Shows information about existing short URLs, including the option to delete.\n        Also shows the live host and port information.\n\n    * /<short url>\n        Redirects to the full URL associated with the supplied short URL.\n\n    * /delete/\n        Used internally to support deletion from the stats/ route.\n\n## Configuration\n\nThe code is all contained within url_shortener.py and various configuration options can be set in the beginning of the file.\n\n## General Notes\n\nThe code was developed and tested using Python 3.8.5, 3.9.4, and 3.9.6. As of this writing it hasn't been tested with other versions, although I suspect Python 3.6+ should work.\n\nThis project was a learning exercise and isn't meant to be production-ready code.\n\n## License\n\nCode and documentation are available according to the MIT License. (See [LICENSE](https://github.com/friendlysapphire/simple_url_shortener/blob/main/LICENSE))\n",
        "bottle==0.12.18\nbottle-sqlite==0.2.0\ncertifi==2021.5.30\nhashids==1.3.1\n",
        4,
        ["python url_shortener.py"],
        "Bottle v0.12.18 server starting up (using WSGIRefServer())...\nListening on http://localhost:8080/\nHit Ctrl-C to quit.",
        "Success"
    ],
}